{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "essential-american",
   "metadata": {},
   "source": [
    "# Darcy equation\n",
    "\n",
    "In this tutorial we present how to solve a Darcy equation with [PyGeoN](https://github.com/compgeo-mox/pygeon) in themoving domain case (the upper boundary will move).  The unkwons are the velocity $u$, the elevation head $h$ and the height of the upper boundary $\\eta$.\n",
    "\n",
    "Let $\\Omega=(0,1)\\times(0,\\eta)$ with boundary $\\partial \\Omega$ and outward unit normal ${\\nu}$. Given \n",
    "$K$ the matrix permeability, we want to solve the following problem: find $(\\bm{u}, h)$ such that\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "K^{-1} {\\bm{u}} + \\nabla h = {0}\\\\\n",
    "S_s \\frac{\\partial{h}}{\\partial t} + \\nabla \\cdot {u} = f\n",
    "\\end{array}\n",
    "&\\text{in } \\Omega\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbb451",
   "metadata": {},
   "source": [
    "In order to solve the problem, we will perfom a change of coordinates to a reference domain $\\hat{\\Omega}=(0,1)^2$ through the (linear) trasnformation $R : \\Omega \\rightarrow \\hat{\\Omega}$ (and its inverse function $D : \\hat{\\Omega} \\rightarrow \\Omega$).\n",
    "Recall that $\\hat{\\nabla}R=(\\nabla D)^{-1}$.\n",
    "\n",
    "Let $\\hat{h}$ and $\\hat{\\bm{u}}$ be $h$ and $\\bm{u}$ respectevely in the reference domain and let $\\hat{K}$ be the transformed permeability matrix, defined as $\\hat{K}=det(\\hat{\\nabla}D) (\\hat{\\nabla} D)^{-1} K (\\hat{\\nabla} D)^{-T}$.\n",
    "\n",
    "The equation describing the motion of $\\partial_{top}\\Omega$ is:\n",
    "$$\n",
    "\n",
    "\\phi \\frac{\\partial \\eta}{\\partial t} = \\hat{u_3} + I(t)\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068fac3",
   "metadata": {},
   "source": [
    "The transformed equations in $\\hat{\\Omega}$ is:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\hat{K}({\\eta})^{-1} {\\hat{u}} + \\hat{\\nabla} \\hat{h} = {0}\\\\\n",
    "\\hat{S}_s \\frac{\\partial{\\hat{h}}}{\\partial t} + \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}} = f\n",
    "\\end{array}\n",
    "&\\text{in } \\hat{\\Omega}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "with boundary conditions:\n",
    "$$ \\hat{h} = \\eta \\text{ on } \\Gamma \\qquad \\hat{h} = \\ell \\text{ on } \\Gamma_D \\qquad \\hat{\\bm{\\nu}} \\cdot \\hat{\\bm{u}} = 0 \\text{ on } \\Gamma_N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b01879",
   "metadata": {},
   "source": [
    "The weak formulation will be:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\int_{\\Omega}\\hat{K}(\\eta)^{-1} {\\bm{\\hat{u}}} \\cdot \\bm{v} \\, d\\Omega - \\int_{\\Omega} h \\hat{\\nabla} \\cdot {\\hat{\\bm{v}}} \\, d\\Omega = - \\int_{\\Gamma_D} h \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega - \\int_{\\Gamma} \\eta \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega\\\\\n",
    "\\int_{\\Omega} \\hat{S}_s \\frac{\\partial{\\hat{h}}}{\\partial t} v \\, d\\Omega + \\int_{\\Omega} \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}} v \\, d\\Omega = \\int_{\\Omega} fv \\, d\\Omega\\\\\n",
    "\\int_{\\Gamma} \\phi \\frac{\\partial \\eta}{\\partial t} v \\, d\\sigma = \\int_{\\Gamma} \\hat{u_3} v \\, d\\sigma + \\int_{\\Gamma} I(t) v \\, d\\sigma\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc7603",
   "metadata": {},
   "source": [
    "For the time discretization, we will employ a backward Euler scheme:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\int_{\\Omega}\\hat{K}(\\eta^{n+1})^{-1} {\\bm{\\hat{u}}^{n+1}} \\cdot \\bm{v} \\, d\\Omega - \\int_{\\Omega} h^{n+1} \\hat{\\nabla} \\cdot {\\hat{\\bm{v}}} \\, d\\Omega = - \\int_{\\Gamma_D} h^{n+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega - \\int_{\\Gamma} \\eta^{n+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega\\\\\n",
    "\\int_{\\Omega} \\hat{S}_s^{n+1} \\frac{\\hat{h}^{n+1} - \\hat{h}^{n}}{\\Delta t} v \\, d\\Omega + \\int_{\\Omega} \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}^{n+1}} v \\, d\\Omega = \\int_{\\Omega} f^{n+1}v \\, d\\Omega\\\\\n",
    "\\int_{\\Gamma} \\phi \\eta^{n+1} v \\, d\\sigma = \\Delta t \\int_{\\Gamma} \\hat{\\bm{u}}^{n+1} \\cdot \\bm{\\nu} v \\, d\\sigma + \\int_{\\Gamma} \\phi \\eta^{n} v \\, d\\sigma + \\Delta t \\int_{\\Gamma} I^{n+1} v \\, d\\sigma\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf928a5",
   "metadata": {},
   "source": [
    "To deal with the non-linear term, we will employ a simple Picard scheme:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\int_{\\Omega}\\hat{K}(\\eta^{n+1}_k)^{-1} {\\bm{\\hat{u}_{k+1}^{n+1}}} \\cdot \\bm{v} \\, d\\Omega - \\int_{\\Omega} h^{n+1}_{k+1} \\hat{\\nabla} \\cdot {\\hat{\\bm{v}}} \\, d\\Omega + \\int_{\\Gamma} \\eta^{n+1}_{k+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega= - \\int_{\\Gamma_D} h^{n+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega\\\\\n",
    "\\Delta t \\int_{\\Omega} \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}^{n+1}_{k+1}} v \\, d\\Omega + \\int_{\\Omega} \\hat{S}_s \\hat{h}^{n+1}_{k+1} v \\, d\\Omega = \\int_{\\Omega} \\hat{S}_s \\hat{h}^{n} v \\, d\\Omega + \\Delta t \\int_{\\Omega} f^{n+1}v \\, d\\Omega\\\\\n",
    "- \\Delta t \\int_{\\Gamma} \\hat{\\bm{u}}^{n+1}_{k+1} \\cdot \\bm{\\nu} v \\, d\\sigma + \\int_{\\Gamma} \\phi \\eta^{n+1}_{k+1} v \\, d\\sigma = \\int_{\\Gamma} \\phi \\eta^{n} v \\, d\\sigma + \\Delta t \\int_{\\Gamma} I^{n+1} v \\, d\\sigma\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615fb33d",
   "metadata": {},
   "source": [
    "The matrix formulation will be:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "M_u(\\bm{\\eta}^{n+1}_{k}) \\bm{u}^{n+1}_{k+1} + B^T\\bm{h}^{n+1}_{k+1} + B_{\\Gamma}^T \\bm{\\eta}^{n+1}_{k+1}= \\bm{BC}^{n+1}\\\\\n",
    "- \\Delta t B \\hat{\\bm{u}}^{n+1}_{k+1} + S_s M_{h} \\bm{\\hat{h}^{n+1}_{k+1}} = \\Delta t \\bm{F}^{n+1} + S_s M_{h} \\bm{\\hat{h}^{n}}\\\\\n",
    "- \\Delta t B_{\\Gamma} \\hat{\\bm{u}}^{n+1}_{k+1} + \\phi M_{\\Gamma} \\bm{\\eta^{n+1}_{k+1}} = \\phi M_{\\Gamma} \\bm{\\eta^{n}} + \\Delta t \\bm{I}^{n+1}\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e31d3b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\n",
    "\\begin{array}{cc} \n",
    "M_u(\\bm{\\eta^{n+1}_k}) & B^T & B_{\\Gamma}^T\\\\\n",
    "-\\Delta t B & S_s M_h & 0\\\\\n",
    "-\\Delta t B_{\\Gamma} & 0 & \\phi M_{\\Gamma}\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{u^{n+1}_{k+1}}\\\\ \n",
    "\\bm{h^{n+1}_{k+1}}\\\\\n",
    "\\bm{\\eta^{n+1}_{k+1}}\n",
    "\\end{array}\n",
    "\\right)\n",
    "=\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{BC}^{n+1}\\\\ \n",
    "\\Delta t \\bm{F}^{n+1} + S_s M_h \\bm{h}^n\\\\\n",
    "\\phi M_{\\Gamma} \\bm{\\eta}^n + \\Delta t \\bm{I}^{n+1}\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60777fa8",
   "metadata": {},
   "source": [
    "We will start to test the method in the case $M_u(\\bm{h_k}^{n+1})=\\bm{I}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa691294",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dietary-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/porepy/numerics/nonlinear/nonlinear_solvers.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from math import ceil, floor, log10, exp, isnan\n",
    "import os, shutil\n",
    "\n",
    "import time\n",
    "import sympy as sp\n",
    "\n",
    "import porepy as pp\n",
    "import pygeon as pg\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1342bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = str(ceil(time.time())) + '_' + 'lagrange_multiplier'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-glossary",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f22221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real domain dimensions\n",
    "A = 3 # Height\n",
    "B = 2 # Domain\n",
    "\n",
    "# Set the number of steps (excluding the initial condition)\n",
    "num_steps = 9\n",
    "\n",
    "# Simulation time length\n",
    "T = 9/48\n",
    "\n",
    "# Time switch conditions (for the boundary condition)\n",
    "dt_D = 3/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c265b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Van Genuchten model parameters ( relative permeability model )\n",
    "theta_s = 0.396\n",
    "theta_r = 0.131\n",
    "\n",
    "alpha = 0.423\n",
    "\n",
    "n = 2.06\n",
    "K_s = 4.96e-2\n",
    "\n",
    "m = 1 - 1/n\n",
    "\n",
    "phi = (theta_s - theta_r)\n",
    "\n",
    "def initial_h_func(x): return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b63bbfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum number of iterations of the non-linear solver\n",
    "max_iterations_per_step = 1000\n",
    "\n",
    "# L-scheme parameter\n",
    "L_h   = 3.501e-2\n",
    "\n",
    "# Relative and absolute tolerances for the non-linear solver\n",
    "abs_tol = 1e-10\n",
    "rel_tol = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3b3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = (T-0) / num_steps\n",
    "N = 20 # 16\n",
    "quad_order = 1\n",
    "\n",
    "# Domain tolerance\n",
    "domain_tolerance = 1 / (10 * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fabe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621e7ae2",
   "metadata": {},
   "source": [
    "### $\\theta$ and $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a00d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symbolic psi\n",
    "psi_var = sp.Symbol('psi', negative=True)\n",
    "\n",
    "# Symbolic Theta\n",
    "theta_expression = theta_r + (theta_s - theta_r) / (1 + (-alpha * psi_var) ** n) ** m\n",
    "effective_saturation = (theta_expression - theta_r) / (theta_s - theta_r)\n",
    "\n",
    "# Symbolic Conductivity K\n",
    "hydraulic_conductivity_expression = K_s * (effective_saturation ** 0.5) * ( 1 - (1 - effective_saturation ** (1 / m)) ** m ) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fca8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta lambda\n",
    "theta_lambda = sp.lambdify(psi_var, theta_expression, 'numpy')\n",
    "\n",
    "# Conductivity tensor lambda\n",
    "conductivity_lambda = sp.lambdify(psi_var, hydraulic_conductivity_expression, 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c2513e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual (and final) theta function\n",
    "def theta(psi):\n",
    "    mask = np.where(psi < 0)\n",
    "    res = np.ones_like(psi) * theta_s\n",
    "    res[mask] = theta_lambda(psi[mask])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conductivity(psi):\n",
    "    if psi >= 0:\n",
    "        return K_s\n",
    "    return conductivity_lambda(psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97631457",
   "metadata": {},
   "source": [
    "### Grid and $V_h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spectacular-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the grid into a mixed-dimensional grid\n",
    "darcy_grid = pp.StructuredTriangleGrid([N * ceil(B), N * round(1)], [B, 1])\n",
    "darcy_grid.compute_geometry()\n",
    "pg.convert_from_pp(darcy_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a0eddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the grid into a mixed-dimensional grid\n",
    "richards_grid = pp.StructuredTriangleGrid([N * ceil(B), N * round(A-1)], [B, 1])\n",
    "richards_grid.compute_geometry()\n",
    "pg.convert_from_pp(richards_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa231fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_grid, boundary_face_map, boundary_node_map = pp.partition.extract_subgrid(darcy_grid, darcy_grid.face_centers[1, :] == 1, faces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0024b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"flow\"\n",
    "\n",
    "darcy_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88c12db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_field    = pg.Lagrange1(key)\n",
    "richards_field = pg.Lagrange1(key)\n",
    "\n",
    "gamma_field    = pg.Lagrange1(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feb51c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_rhs = np.zeros( darcy_grid.num_nodes + richards_grid.num_nodes + boundary_grid.num_nodes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42d1d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_dof    =    darcy_field.ndof( darcy_grid )\n",
    "richards_dof = richards_field.ndof( richards_grid )\n",
    "\n",
    "boundary_dof = gamma_field.ndof( boundary_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d837ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_data = {}\n",
    "richards_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33b2a2",
   "metadata": {},
   "source": [
    "### BC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Restrictor matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_remove_boundary = np.zeros(shape=(darcy_dof - boundary_dof, darcy_dof))\n",
    "darcy_remove_boundary[ np.arange(darcy_dof - boundary_dof), darcy_grid.nodes[1, :] < 1 ] = 1\n",
    "darcy_remove_boundary = sps.csr_matrix(darcy_remove_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "richards_remove_boundary = np.zeros(shape=(richards_dof - boundary_dof, richards_dof))\n",
    "richards_remove_boundary[ np.arange(richards_dof - boundary_dof), richards_grid.nodes[1, :] > 0 ] = 1\n",
    "richards_remove_boundary = sps.csr_matrix(richards_remove_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbe30c",
   "metadata": {},
   "source": [
    "##### Dirichlet (essential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_dirichlet_flag  = np.array(darcy_grid.nodes[0, :] == B, dtype=bool)\n",
    "darcy_dirichlet_value = np.array(darcy_dirichlet_flag, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3d2a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "richards_dirichlet_flag  = np.array(np.logical_and(richards_grid.nodes[1, :] == 1, richards_grid.nodes[0, :] <= 1 ), dtype=bool)\n",
    "richards_dirichlet_value = lambda t: np.array(richards_dirichlet_flag, dtype=float) * min(3.2, 1 + 2.2 * t / dt_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a59184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichlet_flag  = lambda t: np.hstack((darcy_dirichlet_flag, richards_dirichlet_flag, np.zeros(shape=boundary_dof, dtype=bool)))\n",
    "dirichlet_value = lambda t: np.hstack((darcy_dirichlet_value, richards_dirichlet_value(t), np.zeros(shape=boundary_dof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a096f7",
   "metadata": {},
   "source": [
    "##### Neumann (natural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07ef0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full no-flow condition for the Neumann part.... nothing to add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darcy_real_height(eta, heights): \n",
    "    return heights * eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def richards_real_height(eta, heighs): \n",
    "    return heighs * (A - eta) + eta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b55b3f",
   "metadata": {},
   "source": [
    "### Matrix Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab84c0f5",
   "metadata": {},
   "source": [
    "##### Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "960db499",
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_mask = np.zeros(shape=(darcy_dof + richards_dof + boundary_dof), dtype=bool)\n",
    "darcy_mask[ : (darcy_dof) ] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_internal_mask = np.zeros_like(darcy_mask, dtype=bool)\n",
    "darcy_internal_mask[np.where(darcy_grid.nodes[1, :] < 1)[0]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "richards_mask = np.zeros_like(darcy_mask, dtype=bool)\n",
    "richards_mask[(darcy_dof):(darcy_dof + richards_dof)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_mask = np.zeros_like(darcy_mask, dtype=bool)\n",
    "boundary_mask[np.where(darcy_grid.nodes[1, :] == 1)[0]] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8cc76c",
   "metadata": {},
   "source": [
    "##### Finite difference matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecea12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_diff = gamma_field.assemble_diff_matrix( boundary_grid )\n",
    "eta_diff[0,0] = -1\n",
    "eta_diff *= (boundary_grid.num_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d3988",
   "metadata": {},
   "source": [
    "#### Stifness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bac2e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "def find_ordering(coord: np.array):\n",
    "    lx = np.argmin(coord[0, :])\n",
    "    rx = np.argmax(coord[0, :])\n",
    "    mx = np.setdiff1d(np.array([0,1,2]), np.array([lx, rx]))[0]\n",
    "\n",
    "    # Vertical Alignment\n",
    "    if np.abs( coord[0, lx] - coord[0, mx] ) < 1e-7:\n",
    "        # lx and mx vertical aligned, rx no\n",
    "        up =   lx if np.argmax(coord[1, np.array([lx, mx])]) == 0 else mx\n",
    "        down = lx if np.argmin(coord[1, np.array([lx, mx])]) == 0 else mx\n",
    "\n",
    "        if np.abs( coord[1, up] - coord[1, rx] ) < 1e-7:\n",
    "            return [up, down, rx]\n",
    "        else:\n",
    "            return [down, rx, up]\n",
    "    else:\n",
    "        # rx and mx vertical aligned, lx no\n",
    "        up =   rx if np.argmax(coord[1, np.array([rx, mx])]) == 0 else mx\n",
    "        down = rx if np.argmin(coord[1, np.array([rx, mx])]) == 0 else mx\n",
    "\n",
    "        if np.abs( coord[1, up] - coord[1, lx] ) < 1e-7:\n",
    "            return [up, lx, down]\n",
    "        else:\n",
    "            return [down, up, lx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7268754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "def q1():\n",
    "    return np.array([-1, -1])\n",
    "\n",
    "def q2():\n",
    "    return np.array([ 1, 0])\n",
    "\n",
    "def q3():\n",
    "    return np.array([0,  1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4d79750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Darcy_K_func(base_height: float, base_width: float, element_height: float, element_width: float, m: int, ls_eta: float, rs_eta: float, grad_eta: float, x, y):\n",
    "    coord = lambda t: ((m+1) * (1-t) - (m-1) * t) / 2\n",
    "\n",
    "    x3 = base_height + coord(x) * element_height\n",
    "    eta = (1-coord(y)) * ls_eta + coord(y) * rs_eta\n",
    "\n",
    "    chi_x3  = eta\n",
    "    chi_eta = x3\n",
    "\n",
    "    return np.array([[             chi_x3,                            -chi_eta * grad_eta],\n",
    "                     [-chi_eta * grad_eta, (1 + np.power(chi_eta * grad_eta, 2)) / chi_x3]]) * K_s\n",
    "\n",
    "    # This is the full version:\n",
    "    #return np.array([[                  chi_x3 * k11,                                                    k12 - chi_eta * grad_eta * k11],\n",
    "    #                 [k21 - chi_eta * grad_eta * k11, ( k22 + chi_eta * grad_eta * ( chi_eta * grad_eta * k11 - k12 - k21 ) ) / chi_x3 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ede2423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Richards_K_func(base_height: float, base_width: float, element_height: float, element_width: float, m: int, ls_eta: float, rs_eta: float, grad_eta: float, A: float, psi, x, y):\n",
    "    coord = lambda t: ((m+1) * (1-t) - (m-1) * t) / 2\n",
    "\n",
    "    x3 = base_height + coord(x) * element_height\n",
    "    eta = (1-coord(y)) * ls_eta + coord(y) * rs_eta\n",
    "\n",
    "    chi_x3  = A - eta\n",
    "    chi_eta = 2 - x3\n",
    "\n",
    "    return np.array([[             chi_x3,                            -chi_eta * grad_eta],\n",
    "                     [-chi_eta * grad_eta, (1 + np.power(chi_eta * grad_eta, 2)) / chi_x3]]) * conductivity(psi(x,y))\n",
    "\n",
    "    # This is the full version:\n",
    "    #return np.array([[                  chi_x3 * k11,                                                    k12 - chi_eta * grad_eta * k11],\n",
    "    #                 [k21 - chi_eta * grad_eta * k11, ( k22 + chi_eta * grad_eta * ( chi_eta * grad_eta * k11 - k12 - k21 ) ) / chi_x3 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0eb2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_A(coord, sign, ls_eta, rs_eta, grad_eta, darcy, psi=None):\n",
    "    M = np.zeros(shape=(3,3))\n",
    "    m = np.prod(sign)\n",
    "\n",
    "    ordering = find_ordering(coord)\n",
    "\n",
    "    x0 = coord[:, ordering][:, 0]\n",
    "    x1 = coord[:, ordering][:, 1]\n",
    "    x2 = coord[:, ordering][:, 2]\n",
    "    \n",
    "    J_T_1_T = np.array([[x2[1]-x0[1], x0[1]-x1[1]],\n",
    "                        [x0[0]-x2[0], x1[0]-x0[0]]]) / ((x1[0]-x0[0]) * (x2[1]-x0[1]) - (x2[0]-x0[0]) * (x1[1]-x0[1]))\n",
    "    \n",
    "\n",
    "    q_funcs = [J_T_1_T @ q1(), J_T_1_T @ q2(), J_T_1_T @ q3()]\n",
    "\n",
    "    base_height = np.min(coord[1,:])\n",
    "    base_width  = np.min(coord[0, :])\n",
    "\n",
    "    element_height = (np.max(coord[1, :]) - np.min(coord[1, :]))\n",
    "    element_width  = (np.max(coord[0, :]) - np.min(coord[0, :]))\n",
    "\n",
    "    if darcy:\n",
    "        K_local = lambda x,y: Darcy_K_func(base_height, base_width,\n",
    "                        element_height, element_width,\n",
    "                        m,\n",
    "                        ls_eta, rs_eta, grad_eta, x, y)\n",
    "    else:\n",
    "        ordered_psi = psi[ordering]\n",
    "\n",
    "        psi_func = lambda x,y: ordered_psi[0] + (ordered_psi[1] - ordered_psi[0]) * x + (ordered_psi[2] - ordered_psi[0]) * y\n",
    "\n",
    "        K_local = lambda x,y: Richards_K_func(1 + base_height, base_width,\n",
    "                        element_height, element_width,\n",
    "                        m,\n",
    "                        ls_eta, rs_eta, grad_eta, A, psi_func, x, y)\n",
    "        \n",
    "    jacobian = 1 / np.linalg.det( J_T_1_T.T )\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            integrand = lambda ys,x: np.array([q_funcs[i].T @ K_local(x, y) @ q_funcs[j] for y in np.array(ys)])\n",
    "            inside = lambda xs, n: np.array([integrate.fixed_quad(integrand, 0, 1-x, args=(x,), n=n)[0] for x in np.array(xs)])\n",
    "            M[ordering[i], ordering[j]] = integrate.fixed_quad(inside, 0, 1, n=quad_order, args=(quad_order,))[0] * jacobian\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "492cd687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stifness(eta_dofs, domain, h_dofs=None):\n",
    "        \n",
    "    darcy = (domain == darcy_grid)\n",
    "\n",
    "\n",
    "    grad_eta = eta_diff @ eta_dofs\n",
    "\n",
    "    # Map the domain to a reference geometry (i.e. equivalent to compute\n",
    "    # surface coordinates in 1d and 2d)\n",
    "\n",
    "    _, _, sign = sps.find(domain.cell_faces)\n",
    "    _, _, _, _, _, node_coords = pp.map_geometry.map_grid(domain)\n",
    "\n",
    "    # Allocate the data to store matrix entries, that's the most efficient\n",
    "    # way to create a sparse matrix.\n",
    "    size = np.power(domain.dim + 1, 2) * domain.num_cells\n",
    "    rows_I = np.empty(size, dtype=int)\n",
    "    cols_J = np.empty(size, dtype=int)\n",
    "    data_IJ = np.empty(size)\n",
    "    idx = 0\n",
    "\n",
    "    cell_nodes = domain.cell_nodes()\n",
    "\n",
    "    if darcy:\n",
    "        psi_dofs = None\n",
    "    else:\n",
    "        psi_dofs = h_dofs - richards_real_height( np.tile(eta_dofs, ceil(richards_grid.num_nodes / boundary_grid.num_nodes)), richards_grid.nodes[1, :] )\n",
    "\n",
    "    for c in np.arange(domain.num_cells):\n",
    "        # For the current cell retrieve its nodes\n",
    "        loc = slice(cell_nodes.indptr[c], cell_nodes.indptr[c + 1])\n",
    "\n",
    "        nodes_loc = cell_nodes.indices[loc]\n",
    "        coord_loc = node_coords[:, nodes_loc]\n",
    "\n",
    "        eta_cell = np.max(np.where( boundary_grid.nodes[0, :] < domain.cell_centers[0, c] ))\n",
    "\n",
    "        # Compute the stiff-H1 local matrix\n",
    "        mat_A = local_A(coord_loc, sign[loc], eta_dofs[eta_cell], eta_dofs[eta_cell+1], grad_eta[eta_cell], darcy, None if darcy else psi_dofs[nodes_loc])\n",
    "\n",
    "        # Save values for stiff-H1 local matrix in the global structure\n",
    "        cols = np.tile(nodes_loc, (nodes_loc.size, 1))\n",
    "        loc_idx = slice(idx, idx + cols.size)\n",
    "        rows_I[loc_idx] = cols.T.ravel()\n",
    "        cols_J[loc_idx] = cols.ravel()\n",
    "        data_IJ[loc_idx] = mat_A.ravel()\n",
    "        idx += cols.size\n",
    "\n",
    "    # Construct the global matrices\n",
    "    return sps.csc_matrix((data_IJ, (rows_I, cols_J)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a074e8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0496, -0.0248, -0.0248],\n",
       "       [-0.0248,  0.0248,  0.    ],\n",
       "       [-0.0248,  0.    ,  0.0248]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_A(np.array([[0, 1, 0], [0, 0, 1]]), np.array([-1, 1, -1]), 1, 1, 0, True, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.062 , -0.0496, -0.0124],\n",
       "       [-0.0496,  0.0496,  0.    ],\n",
       "       [-0.0124,  0.    ,  0.0124]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_A(np.array([[0, 1, 0], [0, 0, 1]]), np.array([-1, 1, -1]), 1, 1, 0, False, np.array([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e28782",
   "metadata": {},
   "source": [
    "#### Mass matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b746cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_M_h    = darcy_field.assemble_mass_matrix( darcy_grid )\n",
    "richards_M_h = richards_field.assemble_mass_matrix( richards_grid )\n",
    "\n",
    "M_gamma = gamma_field.assemble_mass_matrix( boundary_grid )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de9fa7",
   "metadata": {},
   "source": [
    "#### Projection matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab4a16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_proj    =    darcy_field.eval_at_cell_centers( darcy_grid )\n",
    "richards_proj = richards_field.eval_at_cell_centers( richards_grid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restrictor matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "darcy_restrict_to_boundary = np.zeros(shape=(boundary_dof, darcy_dof))\n",
    "darcy_restrict_to_boundary[np.arange(boundary_dof), darcy_grid.nodes[1, :] == 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "richards_restrict_to_boundary = np.zeros(shape=(boundary_dof, richards_dof))\n",
    "richards_restrict_to_boundary[np.arange(boundary_dof), richards_grid.nodes[1, :] == 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2bceb",
   "metadata": {},
   "source": [
    "### Solve System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abb485ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_directory):\n",
    "    shutil.rmtree(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c91b0b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed rhs\n",
    "fixed_rhs = np.zeros(darcy_dof + richards_dof + boundary_dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d75b1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions\n",
    "sol = [np.zeros_like(fixed_rhs)]\n",
    "sol[-1][darcy_mask]    = darcy_field.interpolate( darcy_grid, initial_h_func )\n",
    "sol[-1][richards_mask] = richards_field.interpolate( richards_grid, initial_h_func )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f2c117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_step(sol, savers, i):\n",
    "\n",
    "    for saver, proj, mask, grid, heights in zip(savers, [darcy_proj, richards_proj], [darcy_mask, richards_mask], [darcy_grid, richards_grid], [darcy_real_height(np.tile(sol[boundary_mask], ceil(darcy_grid.num_nodes / boundary_grid.num_nodes)), darcy_grid.nodes[1,:]), \n",
    "                                                                                                                                                richards_real_height(np.tile(sol[boundary_mask], ceil(richards_grid.num_nodes / boundary_grid.num_nodes)), richards_grid.nodes[1, :])]):\n",
    "        ins = list()\n",
    "\n",
    "        ins.append((grid, \"cell_h\", proj @ sol[mask]))\n",
    "        ins.append((grid, \"cell_p\", proj @ (sol[mask] - heights)))\n",
    "\n",
    "        saver.write_vtu(ins, time_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "354f427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial solution\n",
    "savers = [pp.Exporter(darcy_grid, 'sol_D', folder_name=output_directory), \n",
    "          pp.Exporter(richards_grid, 'sol_R', folder_name=output_directory)]\n",
    "save_step(sol[-1], savers, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_base = os.path.join(output_directory, 'csv')\n",
    "os.mkdir( csv_base )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6036f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0.02083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0001, error L2 relative psi:    0.10879112894742\n",
      "Iteration #0002, error L2 relative psi:    0.01734002530165\n",
      "Iteration #0003, error L2 relative psi:    0.00101291113398\n",
      "Iteration #0004, error L2 relative psi:    0.00010109128447\n",
      "Iteration #0005, error L2 relative psi:    0.00000559248675\n",
      "\n",
      "Time 0.04167\n",
      "Iteration #0001, error L2 relative psi:    0.16706612478749\n",
      "Iteration #0002, error L2 relative psi:    0.04494471227963\n",
      "Iteration #0003, error L2 relative psi:    0.00824740583882\n",
      "Iteration #0004, error L2 relative psi:    0.00095144764166\n",
      "Iteration #0005, error L2 relative psi:    0.00032374043802\n",
      "Iteration #0006, error L2 relative psi:    0.00003569782248\n",
      "Iteration #0007, error L2 relative psi:    0.00001248818125\n",
      "\n",
      "Time 0.0625\n",
      "Iteration #0001, error L2 relative psi:    0.23770071232887\n",
      "Iteration #0002, error L2 relative psi:    0.07994081044150\n",
      "Iteration #0003, error L2 relative psi:    0.02222464989636\n",
      "Iteration #0004, error L2 relative psi:    0.00391600438481\n",
      "Iteration #0005, error L2 relative psi:    0.00151939881657\n",
      "Iteration #0006, error L2 relative psi:    0.00038387953939\n",
      "Iteration #0007, error L2 relative psi:    0.00009652779622\n",
      "Iteration #0008, error L2 relative psi:    0.00003141633397\n",
      "Iteration #0009, error L2 relative psi:    0.00000712220010\n",
      "\n",
      "Time 0.08333\n",
      "Iteration #0001, error L2 relative psi:    0.15842788867469\n",
      "Iteration #0002, error L2 relative psi:    0.02756607781184\n",
      "Iteration #0003, error L2 relative psi:    0.00505271990389\n",
      "Iteration #0004, error L2 relative psi:    0.00148114608808\n",
      "Iteration #0005, error L2 relative psi:    0.00039367850657\n",
      "Iteration #0006, error L2 relative psi:    0.00007959371326\n",
      "Iteration #0007, error L2 relative psi:    0.00002121582408\n",
      "\n",
      "Time 0.10417\n",
      "Iteration #0001, error L2 relative psi:    0.12278503090460\n",
      "Iteration #0002, error L2 relative psi:    0.01726098609419\n",
      "Iteration #0003, error L2 relative psi:    0.00291611022461\n",
      "Iteration #0004, error L2 relative psi:    0.00054599079175\n",
      "Iteration #0005, error L2 relative psi:    0.00014578298369\n",
      "Iteration #0006, error L2 relative psi:    0.00002912257375\n",
      "Iteration #0007, error L2 relative psi:    0.00000458752557\n",
      "\n",
      "Time 0.125\n",
      "Iteration #0001, error L2 relative psi:    0.10075757880825\n",
      "Iteration #0002, error L2 relative psi:    0.01449119025220\n",
      "Iteration #0003, error L2 relative psi:    0.00275691773183\n",
      "Iteration #0004, error L2 relative psi:    0.00047398189289\n",
      "Iteration #0005, error L2 relative psi:    0.00007991409914\n",
      "Iteration #0006, error L2 relative psi:    0.00001626506200\n",
      "\n",
      "Time 0.14583\n",
      "Iteration #0001, error L2 relative psi:    0.08541082688533\n",
      "Iteration #0002, error L2 relative psi:    0.01429580884411\n",
      "Iteration #0003, error L2 relative psi:    0.00351536378983\n",
      "Iteration #0004, error L2 relative psi:    0.00094767932330\n",
      "Iteration #0005, error L2 relative psi:    0.00027190263117\n",
      "Iteration #0006, error L2 relative psi:    0.00008129276964\n",
      "Iteration #0007, error L2 relative psi:    0.00002506029772\n",
      "\n",
      "Time 0.16667\n",
      "Iteration #0001, error L2 relative psi:    0.07388051074366\n",
      "Iteration #0002, error L2 relative psi:    0.01491458784676\n",
      "Iteration #0003, error L2 relative psi:    0.00458290193420\n",
      "Iteration #0004, error L2 relative psi:    0.00157377101515\n",
      "Iteration #0005, error L2 relative psi:    0.00056908946583\n",
      "Iteration #0006, error L2 relative psi:    0.00021068110016\n",
      "Iteration #0007, error L2 relative psi:    0.00007898781857\n",
      "Iteration #0008, error L2 relative psi:    0.00002977540146\n",
      "Iteration #0009, error L2 relative psi:    0.00001125631489\n",
      "\n",
      "Time 0.1875\n",
      "Iteration #0001, error L2 relative psi:    0.06468416933829\n",
      "Iteration #0002, error L2 relative psi:    0.01555698196515\n",
      "Iteration #0003, error L2 relative psi:    0.00573044761765\n",
      "Iteration #0004, error L2 relative psi:    0.00233275425234\n",
      "Iteration #0005, error L2 relative psi:    0.00099023309502\n",
      "Iteration #0006, error L2 relative psi:    0.00042790986990\n",
      "Iteration #0007, error L2 relative psi:    0.00018667490443\n",
      "Iteration #0008, error L2 relative psi:    0.00008181179398\n",
      "Iteration #0009, error L2 relative psi:    0.00003594937411\n",
      "Iteration #0010, error L2 relative psi:    0.00001581890620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time Loop\n",
    "for i in range(1, num_steps+1):\n",
    "    current_time = i * dt\n",
    "    print('Time ' + str(round(current_time, 5)))\n",
    "\n",
    "    # Prepare the solution at the previous time step and ...\n",
    "    prev = sol[-1].copy()\n",
    "\n",
    "    # Prepare the rhs\n",
    "    time_rhs = fixed_rhs.copy()\n",
    "    \n",
    "    time_rhs[darcy_mask] += (phi / dt * darcy_restrict_to_boundary.T @ M_gamma @ darcy_restrict_to_boundary @ prev[darcy_mask])\n",
    "\n",
    "    time_rhs[richards_mask] += richards_M_h @ theta(prev[richards_mask] - richards_real_height(np.tile(prev[boundary_mask], ceil(richards_grid.num_nodes / boundary_grid.num_nodes)), richards_grid.nodes[1, :]) ) / dt\n",
    "    time_rhs[richards_mask] += (phi / dt * richards_restrict_to_boundary.T @ M_gamma @ richards_restrict_to_boundary @ prev[richards_mask])\n",
    "    \n",
    "\n",
    "    debug_savers = [pp.Exporter(darcy_grid,    str(i) + '_sol_D', folder_name=os.path.join(output_directory, 'debug')), \n",
    "                    pp.Exporter(richards_grid, str(i) + '_sol_R', folder_name=os.path.join(output_directory, 'debug'))]\n",
    "    save_step(sol[-1], debug_savers, 0)\n",
    "\n",
    "    # Non-linear loop\n",
    "    for k in range(max_iterations_per_step):\n",
    "        rhs = time_rhs.copy()\n",
    "\n",
    "        rhs[richards_mask] += (L_h * richards_M_h @ prev[richards_mask] - richards_M_h @ theta(prev[richards_mask] - richards_real_height(np.tile(prev[boundary_mask], ceil(richards_grid.num_nodes / boundary_grid.num_nodes)), richards_grid.nodes[1, :]) ) ) / dt\n",
    "\n",
    "        darcy_A_h    = stifness( prev[boundary_mask], darcy_grid )\n",
    "        richards_A_h = stifness( prev[boundary_mask], richards_grid, prev[richards_mask])\n",
    "\n",
    "        darcy_start    = darcy_A_h + phi / dt * darcy_restrict_to_boundary.T @ M_gamma @ darcy_restrict_to_boundary\n",
    "        richards_start = richards_A_h + L_h / dt * richards_M_h + phi / dt * richards_restrict_to_boundary.T @ M_gamma @ richards_restrict_to_boundary\n",
    "\n",
    "        spp = sps.bmat([[               darcy_start,                           None,     darcy_restrict_to_boundary.T],\n",
    "                        [                      None,                 richards_start, -richards_restrict_to_boundary.T],\n",
    "                        [darcy_restrict_to_boundary, -richards_restrict_to_boundary,                             None]], format='csc')\n",
    "\n",
    "\n",
    "        ls = pg.LinearSystem(spp, rhs)\n",
    "        ls.flag_ess_bc(dirichlet_flag(current_time), dirichlet_value(current_time))\n",
    "\n",
    "        current = ls.solve()\n",
    "\n",
    "\n",
    "\n",
    "        # Compute the errors (with eta). Should I consider only psi? Should I compute the error on the \"actual\" psi values or on the dofs\n",
    "        abs_err_psi  = np.sqrt( (current[darcy_mask] - prev[darcy_mask]).T @ darcy_M_h @ (current[darcy_mask] - prev[darcy_mask]) + \n",
    "                               (current[richards_mask] - prev[richards_mask]).T @ richards_M_h @ (current[richards_mask] - prev[richards_mask]) )\n",
    "        abs_err_prev = np.sqrt(prev[darcy_mask].T @ darcy_M_h @ prev[darcy_mask] + prev[richards_mask].T @ richards_M_h @ prev[richards_mask])\n",
    "\n",
    "        print('Iteration #' + format(k+1, '0' + str(ceil(log10(max_iterations_per_step)) + 1) + 'd')\n",
    "              + ', error L2 relative psi: ' + format(abs_err_psi, str(5 + ceil(log10(1 / abs_tol)) + 4)\n",
    "                                                     + '.' + str(ceil(log10(1 / abs_tol)) + 4) + 'f') )\n",
    "\n",
    "\n",
    "        save_step(current, debug_savers, k+1)\n",
    "        \n",
    "        if abs_err_psi < abs_tol + rel_tol * abs_err_prev:\n",
    "            break\n",
    "        else:\n",
    "            prev = None\n",
    "            prev = current.copy()\n",
    "\n",
    "    print('')\n",
    "\n",
    "    sol.append( current.copy() )\n",
    "    save_step(sol[-1], savers, i)\n",
    "\n",
    "    export_name = os.path.join(csv_base, str(i) + '.csv')\n",
    "\n",
    "    with open( export_name, 'w' ) as file:\n",
    "\n",
    "        file.write('x,y,h,p\\n')\n",
    "\n",
    "        et = np.tile(sol[-1][boundary_mask], ceil(darcy_grid.num_nodes / boundary_grid.num_nodes) - 1)\n",
    "        ff = np.where(darcy_grid.nodes[1, :] < 1)[0]\n",
    "        for x,y,h,p in zip( darcy_grid.nodes[0, ff], darcy_grid.nodes[1, ff] * et, sol[-1][darcy_internal_mask], sol[-1][darcy_internal_mask] - darcy_grid.nodes[1, ff] * et):\n",
    "            file.write(f'{x},{y},{h},{p}\\n')\n",
    "\n",
    "        et = np.tile(sol[-1][boundary_mask], ceil(richards_grid.num_nodes / boundary_grid.num_nodes))\n",
    "        for x,y,h,p in zip( richards_grid.nodes[0, :], et + (A-et) * richards_grid.nodes[1, :], sol[-1][richards_mask], sol[-1][richards_mask] - ( et + (A-et) * richards_grid.nodes[1, :] ) ):\n",
    "            file.write(f'{x},{y},{h},{p}\\n')\n",
    "\n",
    "\n",
    "for saver in savers:\n",
    "    saver.write_pvd([t * dt for t in range(int(T/dt)+1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cc1db98167c7fd7d55a1da8057731abc6cd6fe154328a2ae319df8aab4e24d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
