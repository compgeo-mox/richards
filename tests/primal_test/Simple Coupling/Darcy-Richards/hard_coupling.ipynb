{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "essential-american",
   "metadata": {},
   "source": [
    "# Darcy equation\n",
    "\n",
    "In this tutorial we present how to solve an evolutionary Darcy equation with [PyGeoN](https://github.com/compgeo-mox/pygeon).  The unkwons are the velocity $q$ and the pressure $p$.\n",
    "\n",
    "Let $\\Omega=(0,1)^2$ with boundary $\\partial \\Omega$ and outward unit normal ${\\nu}$. Let $(0,T)$ with $10=T>0$ be the overall simulation period. Given \n",
    "$k$ the matrix permeability, we want to solve the following problem: find $({q}, p)$ such that\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "k^{-1} {q} + \\nabla p = {- \\rho g \\nabla y}\\\\\n",
    "p_t + \\nabla \\cdot {q} = f\n",
    "\\end{array}\n",
    "&\\text{in } \\Omega \\times (0,T)\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "with boundary conditions:\n",
    "$$ p = 0 \\text{ on } \\partial_{top} \\Omega \\times (0,T] \\qquad p = \\rho g \\text{ on } \\partial_{bottom} \\Omega \\times (0,T] \\qquad \\nu \\cdot q = 0 \\text{ on } \\partial_{left} \\Omega \\cup \\partial_{right} \\Omega \\times (0,T] $$\n",
    "and initial conditions:\n",
    "$$ p|_{t=0} = (1-y) \\rho g \\text{ in } \\Omega \\qquad q|_{t=0} = 0 \\text{ in } \\Omega $$\n",
    "\n",
    "We present *step-by-step* how to create the grid, declare the problem data, and finally solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-danger",
   "metadata": {},
   "source": [
    "First we import some of the standard modules, like `numpy` and `scipy.sparse`. Since PyGeoN is based on [PorePy](https://github.com/pmgbergen/porepy) we import both modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dietary-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/porepy/numerics/nonlinear/nonlinear_solvers.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import porepy as pp\n",
    "import pygeon as pg\n",
    "\n",
    "import sympy as sp\n",
    "\n",
    "from math import ceil, floor, log10, exp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b085b08e",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spectacular-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum number of iterations of the non-linear solver\n",
    "K = 50\n",
    "\n",
    "# L-scheme parameter\n",
    "L = 3.501e-2 #0.1\n",
    "\n",
    "# Set the mesh refinment\n",
    "N = 40\n",
    "\n",
    "# Set the number of steps (excluding the initial condition)\n",
    "num_steps = 9\n",
    "\n",
    "quad_order = 3\n",
    "\n",
    "# Simulation time length\n",
    "T = 9/48\n",
    "\n",
    "# Time switch conditions (for the boundary condition)\n",
    "dt_D = 3/48\n",
    "\n",
    "# Fluid density\n",
    "rho = 1000\n",
    "\n",
    "# Relative and absolute tolerances for the non-linear solver\n",
    "abs_tol = 1e-10\n",
    "rel_tol = 1e-5\n",
    "\n",
    "# Domain tolerance\n",
    "domain_tolerance = 1 / (10 * N)\n",
    "\n",
    "# Output directory\n",
    "output_directory = 'hard_coupling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_h(x): return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Van Genuchten model parameters ( relative permeability model )\n",
    "theta_s = 0.396\n",
    "theta_r = 0.131\n",
    "\n",
    "alpha = 0.423\n",
    "\n",
    "n = 2.06\n",
    "K_s = 4.96e-2\n",
    "\n",
    "m = 1 - 1/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time step\n",
    "dt   = (T-0)/num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\theta$ and $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symbolic psi\n",
    "psi_var = sp.Symbol('psi', negative=True)\n",
    "\n",
    "# Symbolic Theta\n",
    "theta_expression = theta_r + (theta_s - theta_r) / (1 + (-alpha * psi_var) ** n) ** m\n",
    "effective_saturation = (theta_expression - theta_r) / (theta_s - theta_r)\n",
    "\n",
    "# Symbolic Conductivity K\n",
    "hydraulic_conductivity_expression = K_s * (effective_saturation ** 0.5) * ( 1 - (1 - effective_saturation ** (1 / m)) ** m ) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta lambda\n",
    "theta_lambda = sp.lambdify(psi_var, theta_expression, 'numpy')\n",
    "\n",
    "# Conductivity tensor lambda\n",
    "conductivity_lambda = sp.lambdify(psi_var, hydraulic_conductivity_expression, 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual (and final) theta function\n",
    "def theta(psi):\n",
    "    mask = np.where(psi < 0)\n",
    "    res = np.ones_like(psi) * theta_s\n",
    "    res[mask] = theta_lambda(psi[mask])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual (and final) theta function\n",
    "def conductivity(psi):\n",
    "    if psi < 0:\n",
    "        return conductivity_lambda(psi)\n",
    "    else:\n",
    "        return K_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7805603",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_grid =   pp.StructuredTriangleGrid([2*N, N], [2, 1])\n",
    "bottom_grid.compute_geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_grid    = pp.StructuredTriangleGrid([2*N, 2*N], [2, 1])\n",
    "top_grid.compute_geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40da1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_grid, boundary_face_map, boundary_node_map  = pp.partition.extract_subgrid(bottom_grid, \n",
    "                                                                                    bottom_grid.face_centers[1, :] == 1, \n",
    "                                                                                    faces=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "365807cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"flow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab8743e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_field = pg.Lagrange1(key)\n",
    "top_data = {}\n",
    "\n",
    "top_dof =  top_field.ndof( top_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdbbbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_field = pg.Lagrange1(key)\n",
    "bottom_data = {}\n",
    "\n",
    "bottom_dof = bottom_field.ndof( bottom_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae57861",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_field = pg.Lagrange1(key)\n",
    "boundary_data = {}\n",
    "\n",
    "boundary_dof = boundary_field.ndof( boundary_grid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrictor Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_delete_boundary_dof = np.zeros( shape=(bottom_dof - boundary_dof, bottom_dof) )\n",
    "bottom_delete_boundary_dof[np.arange(bottom_dof - boundary_dof), bottom_grid.nodes[1, :] < 1] = 1\n",
    "bottom_delete_boundary_dof = sps.csr_matrix(bottom_delete_boundary_dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_isolate_boundary_dof = np.zeros(shape=(boundary_dof, bottom_dof))\n",
    "bottom_isolate_boundary_dof[np.arange(boundary_dof), bottom_grid.nodes[1, :] == 1] = 1\n",
    "bottom_isolate_boundary_dof = sps.csr_matrix(bottom_isolate_boundary_dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_delete_boundary_dof = np.zeros( shape=(top_dof - boundary_dof, top_dof) )\n",
    "top_delete_boundary_dof[np.arange(top_dof - boundary_dof), top_grid.nodes[1, :] > 0] = 1\n",
    "top_delete_boundary_dof = sps.csr_matrix(top_delete_boundary_dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_isolate_boundary_dof = np.zeros(shape=(boundary_dof, top_dof))\n",
    "top_isolate_boundary_dof[np.arange(boundary_dof), top_grid.nodes[1, :] == 0] = 1\n",
    "top_isolate_boundary_dof = sps.csr_matrix(top_isolate_boundary_dof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_dirichlet_flag  = np.array(bottom_delete_boundary_dof @ np.logical_and( bottom_grid.nodes[0, :] == 2, bottom_grid.nodes[1, :] < 1 ), dtype=bool)\n",
    "bot_dirichlet_value = np.array(bot_dirichlet_flag, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dirichlet_flag  = np.array(top_delete_boundary_dof @ np.logical_and( top_grid.nodes[1, :] == 1, top_grid.nodes[0, :] < 1 ), dtype=bool)\n",
    "top_dirichlet_value = lambda t: np.array(top_dirichlet_flag, dtype=float) * min( 3.2, 1 + 2.2 * t / dt_D )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichlet_flag  = np.hstack(( bot_dirichlet_flag, np.zeros(shape=boundary_dof, dtype=bool), top_dirichlet_flag ))\n",
    "dirichlet_value = lambda t: np.hstack(( bot_dirichlet_value, np.zeros(shape=boundary_dof), top_dirichlet_value(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projection matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0048c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_proj    = top_field.eval_at_cell_centers( top_grid )\n",
    "bottom_proj = bottom_field.eval_at_cell_centers( bottom_grid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stifness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "def find_ordering(coord: np.array):\n",
    "    lx = np.argmin(coord[0, :])\n",
    "    rx = np.argmax(coord[0, :])\n",
    "    mx = np.setdiff1d(np.array([0,1,2]), np.array([lx, rx]))[0]\n",
    "\n",
    "    # Vertical Alignment\n",
    "    if np.abs( coord[0, lx] - coord[0, mx] ) < 1e-7:\n",
    "        # lx and mx vertical aligned, rx no\n",
    "        up =   lx if np.argmax(coord[1, np.array([lx, mx])]) == 0 else mx\n",
    "        down = lx if np.argmin(coord[1, np.array([lx, mx])]) == 0 else mx\n",
    "\n",
    "        if np.abs( coord[1, up] - coord[1, rx] ) < 1e-7:\n",
    "            return [up, down, rx]\n",
    "        else:\n",
    "            return [down, rx, up]\n",
    "    else:\n",
    "        # rx and mx vertical aligned, lx no\n",
    "        up =   rx if np.argmax(coord[1, np.array([rx, mx])]) == 0 else mx\n",
    "        down = rx if np.argmin(coord[1, np.array([rx, mx])]) == 0 else mx\n",
    "\n",
    "        if np.abs( coord[1, up] - coord[1, lx] ) < 1e-7:\n",
    "            return [up, lx, down]\n",
    "        else:\n",
    "            return [down, up, lx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darcy_local_A(coord):\n",
    "\n",
    "    ordering = find_ordering(coord)\n",
    "\n",
    "    x0 = coord[:, ordering][:, 0]\n",
    "    x1 = coord[:, ordering][:, 1]\n",
    "    x2 = coord[:, ordering][:, 2]\n",
    "    \n",
    "    J_T_1_T = np.array([[x2[1]-x0[1], x0[1]-x1[1]],\n",
    "                        [x0[0]-x2[0], x1[0]-x0[0]]]) / ((x1[0]-x0[0]) * (x2[1]-x0[1]) - (x2[0]-x0[0]) * (x1[1]-x0[1]))\n",
    "    \n",
    "\n",
    "    q_funcs = [J_T_1_T @ np.array([-1, -1]), J_T_1_T @ np.array([ 1, 0]), J_T_1_T @ np.array([0,  1])]\n",
    "\n",
    "    M = np.zeros(shape=(3,3))\n",
    "\n",
    "    jacobian = 1 / np.linalg.det( J_T_1_T.T )\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            M[ ordering[i], ordering[j] ] = q_funcs[j].T @ np.array([[1, 0], [0, 1]]) @ q_funcs[i] * jacobian * K_s / 2\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def richards_local_A(coord, psi):\n",
    "    ordering = find_ordering(coord)\n",
    "\n",
    "    x0 = coord[:, ordering][:, 0]\n",
    "    x1 = coord[:, ordering][:, 1]\n",
    "    x2 = coord[:, ordering][:, 2]\n",
    "    \n",
    "    J_T_1_T = np.array([[x2[1]-x0[1], x0[1]-x1[1]],\n",
    "                        [x0[0]-x2[0], x1[0]-x0[0]]]) / ((x1[0]-x0[0]) * (x2[1]-x0[1]) - (x2[0]-x0[0]) * (x1[1]-x0[1]))\n",
    "    \n",
    "\n",
    "    q_funcs = [J_T_1_T @ np.array([-1, -1]), J_T_1_T @ np.array([ 1, 0]), J_T_1_T @ np.array([0,  1])]\n",
    "\n",
    "    M = np.zeros(shape=(3,3))\n",
    "\n",
    "    jacobian = 1 / np.linalg.det( J_T_1_T.T )\n",
    "    ordered_psi = psi[ordering]\n",
    "\n",
    "    psi_fun = lambda x,y: ordered_psi[0] + (ordered_psi[1] - ordered_psi[0]) * x + (ordered_psi[2] - ordered_psi[0]) * y\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            integrand = lambda ys,x: np.array([conductivity(psi_fun(x,y)) for y in np.array(ys)])\n",
    "            inside = lambda xs, n: np.array([integrate.fixed_quad(integrand, 0, 1-x, args=(x,), n=n)[0] for x in np.array(xs)])\n",
    "            tmp = integrate.fixed_quad(inside, 0, 1, n=quad_order, args=(quad_order,))[0]\n",
    "\n",
    "            M[ ordering[i], ordering[j] ] = tmp * q_funcs[j].T @ np.array([[2, 0], [0, 1/2]]) @ q_funcs[i] * jacobian\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0496, -0.0248, -0.0248],\n",
       "       [-0.0248,  0.0248,  0.    ],\n",
       "       [-0.0248,  0.    ,  0.0248]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darcy_local_A(np.array([[0, 1, 0], [0, 0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.062 , -0.0496, -0.0124],\n",
       "       [-0.0496,  0.0496,  0.    ],\n",
       "       [-0.0124,  0.    ,  0.0124]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "richards_local_A(np.array([[0, 1, 0], [0, 0, 1]]), np.array([1,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_mass(coord):\n",
    "    ordering = find_ordering(coord)\n",
    "\n",
    "    x0 = coord[:, ordering][:, 0]\n",
    "    x1 = coord[:, ordering][:, 1]\n",
    "    x2 = coord[:, ordering][:, 2]\n",
    "\n",
    "    qs = [(lambda x,y: 1-x-y), (lambda x,y: x), (lambda x,y: y)]\n",
    "    \n",
    "    J = np.array([[x1[0]-x0[0], x2[0]-x0[0]],\n",
    "                  [x1[1]-x0[1], x2[1]-x0[1]]])\n",
    "    \n",
    "    jacobian = np.linalg.det(J)\n",
    "    M = np.zeros(shape=(3,3))\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            integrand = lambda ys,x: np.array([qs[j](x,y) * qs[i](x,y) for y in np.array(ys)])\n",
    "            inside = lambda xs, n: np.array([integrate.fixed_quad(integrand, 0, 1-x, args=(x,), n=n)[0] for x in np.array(xs)])\n",
    "            tmp = integrate.fixed_quad(inside, 0, 1, n=2, args=(2,))[0]\n",
    "\n",
    "            M[ ordering[i], ordering[j] ] = tmp * jacobian\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08333333, 0.04166667, 0.04166667],\n",
       "       [0.04166667, 0.08333333, 0.04166667],\n",
       "       [0.04166667, 0.04166667, 0.08333333]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_mass(np.array([[0, 1, 0], [0, 0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_stifness(psi):\n",
    "    \n",
    "    size = np.power(bottom_grid.dim + 1, 2) * bottom_grid.num_cells + np.power(top_grid.dim + 1, 2) * top_grid.num_cells\n",
    "    rows_I = np.empty(size, dtype=int)\n",
    "    cols_J = np.empty(size, dtype=int)\n",
    "    data_IJ = np.empty(size)\n",
    "    idx = 0\n",
    "\n",
    "    for subdomain, base in zip([bottom_grid, top_grid], [0, boundary_grid.num_nodes * N]):\n",
    "        _, _, _, _, _, node_coords = pp.map_geometry.map_grid(subdomain)\n",
    "\n",
    "        # Allocate the data to store matrix entries, that's the most efficient\n",
    "        # way to create a sparse matrix.\n",
    "\n",
    "        cell_nodes = subdomain.cell_nodes()\n",
    "\n",
    "        for c in np.arange(subdomain.num_cells):\n",
    "            # For the current cell retrieve its nodes\n",
    "            loc = slice(cell_nodes.indptr[c], cell_nodes.indptr[c + 1])\n",
    "\n",
    "            nodes_loc = cell_nodes.indices[loc]\n",
    "            coord_loc = node_coords[:, nodes_loc]\n",
    "\n",
    "            # Compute the stiff-H1 local matrix\n",
    "\n",
    "            if subdomain == bottom_grid:\n",
    "                A = darcy_local_A(coord_loc)\n",
    "            else:\n",
    "                A = richards_local_A(coord_loc, psi[nodes_loc])\n",
    "\n",
    "            # Save values for stiff-H1 local matrix in the global structure\n",
    "            cols = base + np.tile(nodes_loc, (nodes_loc.size, 1))\n",
    "\n",
    "            loc_idx = slice(idx, idx + cols.size)\n",
    "            rows_I[loc_idx] = cols.T.ravel()\n",
    "            cols_J[loc_idx] = cols.ravel()\n",
    "            data_IJ[loc_idx] = A.ravel()\n",
    "            idx += cols.size\n",
    "\n",
    "    # Construct the global matrices\n",
    "    return sps.csc_matrix((data_IJ, (rows_I, cols_J)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mass():\n",
    "    \n",
    "    size = np.power(bottom_grid.dim + 1, 2) * bottom_grid.num_cells + np.power(top_grid.dim + 1, 2) * top_grid.num_cells\n",
    "    rows_I = np.empty(size, dtype=int)\n",
    "    cols_J = np.empty(size, dtype=int)\n",
    "    data_IJ = np.empty(size)\n",
    "    idx = 0\n",
    "\n",
    "    for subdomain, base, mult in zip([bottom_grid, top_grid], [0, boundary_grid.num_nodes * N], [1,2]):\n",
    "        _, _, _, _, _, node_coords = pp.map_geometry.map_grid(subdomain)\n",
    "\n",
    "        # Allocate the data to store matrix entries, that's the most efficient\n",
    "        # way to create a sparse matrix.\n",
    "\n",
    "        cell_nodes = subdomain.cell_nodes()\n",
    "\n",
    "        for c in np.arange(subdomain.num_cells):\n",
    "            # For the current cell retrieve its nodes\n",
    "            loc = slice(cell_nodes.indptr[c], cell_nodes.indptr[c + 1])\n",
    "\n",
    "            nodes_loc = cell_nodes.indices[loc]\n",
    "            coord_loc = node_coords[:, nodes_loc]\n",
    "\n",
    "            # Compute the stiff-H1 local matrix\n",
    "            \n",
    "            A = local_mass(coord_loc) * mult\n",
    "\n",
    "            # Save values for stiff-H1 local matrix in the global structure\n",
    "            cols = base + np.tile(nodes_loc, (nodes_loc.size, 1))\n",
    "\n",
    "            loc_idx = slice(idx, idx + cols.size)\n",
    "            rows_I[loc_idx] = cols.T.ravel()\n",
    "            cols_J[loc_idx] = cols.ravel()\n",
    "            data_IJ[loc_idx] = A.ravel()\n",
    "            idx += cols.size\n",
    "\n",
    "    # Construct the global matrices\n",
    "    return sps.csc_matrix((data_IJ, (rows_I, cols_J)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45b3ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble initial solution\n",
    "initial_solution = np.zeros(top_dof + bottom_dof - boundary_dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_mask = np.zeros_like(initial_solution, dtype=bool)\n",
    "bottom_mask[ : (bottom_dof) ] = True\n",
    "\n",
    "internal_bottom_mask = np.zeros_like(bottom_mask, dtype=bool)\n",
    "internal_bottom_mask[ : (bottom_dof - boundary_dof)] = True\n",
    "\n",
    "top_mask = np.zeros_like(initial_solution, dtype=bool)\n",
    "top_mask[(bottom_dof - boundary_dof) : ] = True\n",
    "\n",
    "internal_top_mask = np.zeros_like(bottom_mask, dtype=bool)\n",
    "internal_top_mask[ bottom_dof : ] = True\n",
    "\n",
    "boundary_mask = np.zeros_like(bottom_mask, dtype=bool)\n",
    "boundary_mask[(bottom_dof - boundary_dof) : bottom_dof] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f174d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_solution[top_mask]    =    top_field.interpolate(   top_grid, lambda x: 1)\n",
    "initial_solution[bottom_mask] = bottom_field.interpolate(bottom_grid, lambda x: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d786595",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_saver    = pp.Exporter(top_grid,    \"top_sol\", folder_name=output_directory)\n",
    "bottom_saver = pp.Exporter(bottom_grid, \"bottom_sol\", folder_name=output_directory)\n",
    "\n",
    "def save_step(current_sol, step):\n",
    "    ins = list()\n",
    "\n",
    "    ins.append((top_grid, \"cell_h\", top_proj @ current_sol[top_mask]))\n",
    "    ins.append((top_grid, \"cell_p\", top_proj @ (current_sol[top_mask] - 1 - top_grid.nodes[1, :] * 2)))\n",
    "    top_saver.write_vtu(ins, time_step=step)\n",
    "\n",
    "    ins = list()\n",
    "\n",
    "    ins.append((bottom_grid, \"cell_h\", bottom_proj @ current_sol[bottom_mask]))\n",
    "    ins.append((bottom_grid, \"cell_p\", bottom_proj @ (current_sol[bottom_mask] - bottom_grid.nodes[1, :])))\n",
    "    bottom_saver.write_vtu(ins, time_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf8b64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_directory):\n",
    "    shutil.rmtree(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "subtle-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the problem\n",
    "\n",
    "sol = [initial_solution]\n",
    "\n",
    "t = 0\n",
    "\n",
    "save_step(sol[-1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_base = os.path.join(output_directory, 'csv')\n",
    "\n",
    "if os.path.exists(csv_base):\n",
    "    shutil.rmtree(csv_base)\n",
    "    \n",
    "os.mkdir(csv_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_mass = global_mass()\n",
    "top_mass = glob_mass[top_mask, :][:, top_mask]\n",
    "bottom_mass = glob_mass[bottom_mask, :][:, bottom_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0.02083\n",
      "Iteration #001, error L2 relative psi:    0.12573597055050\n",
      "Iteration #002, error L2 relative psi:    0.02079067102851\n",
      "Iteration #003, error L2 relative psi:    0.00137023599990\n",
      "Iteration #004, error L2 relative psi:    0.00015326008110\n",
      "Iteration #005, error L2 relative psi:    0.00001044186161\n",
      "\n",
      "Time 0.04167\n",
      "Iteration #001, error L2 relative psi:    0.19529748926553\n",
      "Iteration #002, error L2 relative psi:    0.05235463142435\n",
      "Iteration #003, error L2 relative psi:    0.00957800772739\n",
      "Iteration #004, error L2 relative psi:    0.00120371632954\n",
      "Iteration #005, error L2 relative psi:    0.00039739159484\n",
      "Iteration #006, error L2 relative psi:    0.00004729806294\n",
      "Iteration #007, error L2 relative psi:    0.00001679188012\n",
      "\n",
      "Time 0.0625\n",
      "Iteration #001, error L2 relative psi:    0.27753939606979\n",
      "Iteration #002, error L2 relative psi:    0.09115409920040\n",
      "Iteration #003, error L2 relative psi:    0.02486223272082\n",
      "Iteration #004, error L2 relative psi:    0.00432859333192\n",
      "Iteration #005, error L2 relative psi:    0.00178503903761\n",
      "Iteration #006, error L2 relative psi:    0.00042498436002\n",
      "Iteration #007, error L2 relative psi:    0.00011750714052\n",
      "Iteration #008, error L2 relative psi:    0.00003733300467\n",
      "Iteration #009, error L2 relative psi:    0.00000839172672\n",
      "\n",
      "Time 0.08333\n",
      "Iteration #001, error L2 relative psi:    0.18459421617789\n",
      "Iteration #002, error L2 relative psi:    0.02970051371118\n",
      "Iteration #003, error L2 relative psi:    0.00543458090512\n",
      "Iteration #004, error L2 relative psi:    0.00189429500708\n",
      "Iteration #005, error L2 relative psi:    0.00043435913531\n",
      "Iteration #006, error L2 relative psi:    0.00009635667507\n",
      "Iteration #007, error L2 relative psi:    0.00002925686601\n",
      "Iteration #008, error L2 relative psi:    0.00000613797716\n",
      "\n",
      "Time 0.10417\n",
      "Iteration #001, error L2 relative psi:    0.14445051563416\n",
      "Iteration #002, error L2 relative psi:    0.01585671209743\n",
      "Iteration #003, error L2 relative psi:    0.00268898098924\n",
      "Iteration #004, error L2 relative psi:    0.00078066241136\n",
      "Iteration #005, error L2 relative psi:    0.00016567225292\n",
      "Iteration #006, error L2 relative psi:    0.00002678456441\n",
      "\n",
      "Time 0.125\n",
      "Iteration #001, error L2 relative psi:    0.12001261117570\n",
      "Iteration #002, error L2 relative psi:    0.01087091245373\n",
      "Iteration #003, error L2 relative psi:    0.00149989427991\n",
      "Iteration #004, error L2 relative psi:    0.00025608499708\n",
      "Iteration #005, error L2 relative psi:    0.00005681727561\n",
      "Iteration #006, error L2 relative psi:    0.00000861599188\n",
      "\n",
      "Time 0.14583\n",
      "Iteration #001, error L2 relative psi:    0.10323263453601\n",
      "Iteration #002, error L2 relative psi:    0.00914984433007\n",
      "Iteration #003, error L2 relative psi:    0.00143179678924\n",
      "Iteration #004, error L2 relative psi:    0.00023787644617\n",
      "Iteration #005, error L2 relative psi:    0.00005464929282\n",
      "Iteration #006, error L2 relative psi:    0.00001482596254\n",
      "\n",
      "Time 0.16667\n",
      "Iteration #001, error L2 relative psi:    0.09085077145156\n",
      "Iteration #002, error L2 relative psi:    0.00869019933516\n",
      "Iteration #003, error L2 relative psi:    0.00175531856275\n",
      "Iteration #004, error L2 relative psi:    0.00045269117556\n",
      "Iteration #005, error L2 relative psi:    0.00013593302978\n",
      "Iteration #006, error L2 relative psi:    0.00004449753779\n",
      "Iteration #007, error L2 relative psi:    0.00001874427512\n",
      "\n",
      "Time 0.1875\n",
      "Iteration #001, error L2 relative psi:    0.08125468910521\n",
      "Iteration #002, error L2 relative psi:    0.00870324477103\n",
      "Iteration #003, error L2 relative psi:    0.00208471089833\n",
      "Iteration #004, error L2 relative psi:    0.00064978804377\n",
      "Iteration #005, error L2 relative psi:    0.00022868536173\n",
      "Iteration #006, error L2 relative psi:    0.00008850769757\n",
      "Iteration #007, error L2 relative psi:    0.00004117893861\n",
      "Iteration #008, error L2 relative psi:    0.00002346125502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time Loop\n",
    "for step in range(1, ceil(T/dt) + 1):\n",
    "    current_time = step * dt\n",
    "    print('Time ' + str(round(current_time, 5)))\n",
    "    \n",
    "    time_rhs = np.zeros_like(sol[-1])\n",
    "\n",
    "    time_rhs[top_mask] += (top_mass @ theta(sol[-1][top_mask] - (1 + top_grid.nodes[1,:] * 2))) / dt\n",
    "\n",
    "    prev = sol[-1]\n",
    "\n",
    "    for k in range(K):\n",
    "        rhs = time_rhs.copy()\n",
    "\n",
    "        rhs[top_mask] += L * top_mass @ prev[top_mask] / dt\n",
    "        rhs[top_mask] -= (top_mass @ theta(prev[top_mask] - (1 + top_grid.nodes[1,:] * 2))) / dt\n",
    "        #rhs[internal_bottom_mask] += L / dt * bottom_delete_boundary_dof @ bottom_mass @ bottom_delete_boundary_dof.T @ prev[internal_bottom_mask]\n",
    "\n",
    "        global_stif = global_stifness( prev[top_mask] - (1 + top_grid.nodes[1,:] * 2) )\n",
    "\n",
    "        bottom_mat = global_stif[bottom_mask, :][:, bottom_mask] #+ L / dt * bottom_mass\n",
    "        top_mat    = global_stif[top_mask, :][:, top_mask] + L / dt * top_mass\n",
    "        mid_mat = global_stif[boundary_mask, :][:, boundary_mask] + L / dt * glob_mass[boundary_mask, :][:, boundary_mask]\n",
    "        \n",
    "        spp = sps.bmat([[    bottom_delete_boundary_dof @ bottom_mat @ bottom_delete_boundary_dof.T, bottom_delete_boundary_dof @ bottom_mat @ bottom_isolate_boundary_dof.T,                                                             None],\n",
    "                        [ bottom_isolate_boundary_dof @ bottom_mat.T @ bottom_delete_boundary_dof.T,                                                                 mid_mat, top_isolate_boundary_dof @ top_mat.T @ top_delete_boundary_dof.T],\n",
    "                        [                                                                      None,          top_delete_boundary_dof @ top_mat @ top_isolate_boundary_dof.T,    top_delete_boundary_dof @ top_mat @ top_delete_boundary_dof.T]], format = 'csc')\n",
    "        \n",
    "        ls = pg.LinearSystem(spp, rhs)\n",
    "        ls.flag_ess_bc(dirichlet_flag, dirichlet_value(current_time))\n",
    "\n",
    "        current = ls.solve()\n",
    "\n",
    "        # Check if we have reached convergence\n",
    "        rel_err_psi  = np.sqrt( (current - prev).T @ glob_mass @ (current - prev) )\n",
    "        abs_err_prev = np.sqrt( prev.T @ glob_mass @ prev )\n",
    "\n",
    "        # Log message with error and current iteration\n",
    "        print('Iteration #' + format(k+1, '0' + str(ceil(log10(K)) + 1) + 'd') + ', error L2 relative psi: ' \n",
    "              + format(rel_err_psi, str(5 + ceil(log10(1 / abs_tol)) + 4) + '.' + str(ceil(log10(1 / abs_tol)) + 4) + 'f') )\n",
    "        \n",
    "        if rel_err_psi > abs_tol + rel_tol * abs_err_prev:\n",
    "            prev = current.copy()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    sol.append( current )\n",
    "\n",
    "    save_step(sol[-1], step)\n",
    "    print('')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be2c79",
   "metadata": {},
   "source": [
    "bottom_mat = stifness(bottom_grid, None)\n",
    "\n",
    "# Time Loop\n",
    "for step in range(1, ceil(T/dt) + 1):\n",
    "    current_time = step * dt\n",
    "    print('Time ' + str(round(current_time, 5)))\n",
    "    \n",
    "    time_rhs = np.zeros_like(sol[-1])\n",
    "\n",
    "    time_rhs[top_mask] += (top_mass @ theta(sol[-1][top_mask] - top_grid.nodes[1,:] - 1)) / dt\n",
    "\n",
    "    prev = sol[-1]\n",
    "\n",
    "    for k in range(K):\n",
    "        rhs = time_rhs.copy()\n",
    "\n",
    "        rhs[top_mask] += L * top_mass @ prev[top_mask] / dt\n",
    "        rhs[top_mask] -= (top_mass @ theta(prev[top_mask] - top_grid.nodes[1,:] - 1)) / dt\n",
    "\n",
    "        top_mat    = stifness(top_grid, prev[top_mask] - top_grid.nodes[1,:] - 1) + L / dt * top_mass\n",
    "        mid_mat = top_isolate_boundary_dof @ top_mat @ top_isolate_boundary_dof.T + bottom_isolate_boundary_dof @ bottom_mat @ bottom_isolate_boundary_dof.T\n",
    "\n",
    "        spp = sps.bmat([[    bottom_delete_boundary_dof @ bottom_mat @ bottom_delete_boundary_dof.T, bottom_delete_boundary_dof @ bottom_mat @ bottom_isolate_boundary_dof.T,                                                             None],\n",
    "                        [ bottom_isolate_boundary_dof @ bottom_mat.T @ bottom_delete_boundary_dof.T,                                                                 mid_mat, top_isolate_boundary_dof @ top_mat.T @ top_delete_boundary_dof.T],\n",
    "                        [                                                                      None,          top_delete_boundary_dof @ top_mat @ top_isolate_boundary_dof.T,    top_delete_boundary_dof @ top_mat @ top_delete_boundary_dof.T]], format = 'csc')\n",
    "        \n",
    "        ls = pg.LinearSystem(spp, rhs)\n",
    "        ls.flag_ess_bc(dirichlet_flag, dirichlet_value(current_time))\n",
    "\n",
    "        current = ls.solve()\n",
    "\n",
    "        # Check if we have reached convergence\n",
    "        rel_err_psi  = np.sqrt( (current - prev)[top_mask].T @ top_mass @ (current - prev)[top_mask] + (current - prev)[bottom_mask].T @ bottom_mass @ (current - prev)[bottom_mask] )\n",
    "        abs_err_prev = np.sqrt( (prev)[top_mask].T @ top_mass @ (prev)[top_mask] + (prev)[bottom_mask].T @ bottom_mass @ (prev)[bottom_mask] )\n",
    "\n",
    "        # Log message with error and current iteration\n",
    "        print('Iteration #' + format(k+1, '0' + str(ceil(log10(K)) + 1) + 'd') + ', error L2 relative psi: ' \n",
    "              + format(rel_err_psi, str(5 + ceil(log10(1 / abs_tol)) + 4) + '.' + str(ceil(log10(1 / abs_tol)) + 4) + 'f') )\n",
    "        \n",
    "        if rel_err_psi > abs_tol + rel_tol * abs_err_prev:\n",
    "            prev = current.copy()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    sol.append( current )\n",
    "\n",
    "    save_step(sol[-1], step)\n",
    "    print('')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('3.10.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cc1db98167c7fd7d55a1da8057731abc6cd6fe154328a2ae319df8aab4e24d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
