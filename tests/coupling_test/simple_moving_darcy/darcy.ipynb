{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "essential-american",
   "metadata": {},
   "source": [
    "# Darcy equation\n",
    "\n",
    "In this tutorial we present how to solve a Darcy equation with [PyGeoN](https://github.com/compgeo-mox/pygeon) in themoving domain case (the upper boundary will move).  The unkwons are the velocity $u$, the elevation head $h$ and the height of the upper boundary $\\eta$.\n",
    "\n",
    "Let $\\Omega=(0,1)\\times(0,\\eta)$ with boundary $\\partial \\Omega$ and outward unit normal ${\\nu}$. Given \n",
    "$K$ the matrix permeability, we want to solve the following problem: find $(\\bm{u}, h)$ such that\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "K^{-1} {\\bm{u}} + \\nabla h = {0}\\\\\n",
    "S_s \\frac{\\partial{h}}{\\partial t} + \\nabla \\cdot {u} = f\n",
    "\\end{array}\n",
    "&\\text{in } \\Omega\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbb451",
   "metadata": {},
   "source": [
    "In order to solve the problem, we will perfom a change of coordinates to a reference domain $\\hat{\\Omega}=(0,1)^2$ through the (linear) trasnformation $R : \\Omega \\rightarrow \\hat{\\Omega}$ (and its inverse function $D : \\hat{\\Omega} \\rightarrow \\Omega$).\n",
    "Recall that $\\hat{\\nabla}R=(\\nabla D)^{-1}$.\n",
    "\n",
    "Let $\\hat{h}$ and $\\hat{\\bm{u}}$ be $h$ and $\\bm{u}$ respectevely in the reference domain and let $\\hat{K}$ be the transformed permeability matrix, defined as $\\hat{K}=det(\\hat{\\nabla}D) (\\hat{\\nabla} D)^{-1} K (\\hat{\\nabla} D)^{-T}$.\n",
    "\n",
    "The equation describing the motion of $\\partial_{top}\\Omega$ is:\n",
    "$$\n",
    "\n",
    "\\phi \\frac{\\partial \\eta}{\\partial t} = \\hat{u_3} + I(t)\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068fac3",
   "metadata": {},
   "source": [
    "The transformed equations in $\\hat{\\Omega}$ is:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\hat{K}(\\hat{h})^{-1} {\\hat{u}} + \\hat{\\nabla} \\hat{h} = {0}\\\\\n",
    "\\hat{S}_s \\frac{\\partial{\\hat{h}}}{\\partial t} + \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}} = f\n",
    "\\end{array}\n",
    "&\\text{in } \\hat{\\Omega}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "with boundary conditions:\n",
    "$$ \\hat{h} = \\eta \\text{ on } \\Gamma \\qquad \\hat{h} = \\ell \\text{ on } \\Gamma_D \\qquad \\hat{\\bm{\\nu}} \\cdot \\hat{\\bm{u}} = 0 \\text{ on } \\Gamma_N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b01879",
   "metadata": {},
   "source": [
    "The weak formulation will be:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\int_{\\Omega}\\hat{K}(\\hat{h})^{-1} {\\bm{\\hat{u}}} \\cdot \\bm{v} \\, d\\Omega - \\int_{\\Omega} h \\hat{\\nabla} \\cdot {\\hat{\\bm{v}}} \\, d\\Omega = - \\int_{\\Gamma_D} h \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega - \\int_{\\Gamma} \\eta \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega\\\\\n",
    "\\int_{\\Omega} \\hat{S}_s \\frac{\\partial{\\hat{h}}}{\\partial t} v \\, d\\Omega + \\int_{\\Omega} \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}} v \\, d\\Omega = \\int_{\\Omega} fv \\, d\\Omega\\\\\n",
    "\\int_{\\Gamma} \\phi \\frac{\\partial \\eta}{\\partial t} v \\, d\\sigma = \\int_{\\Gamma} \\hat{u_3} v \\, d\\sigma + \\int_{\\Gamma} I(t) v \\, d\\sigma\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc7603",
   "metadata": {},
   "source": [
    "For the time discretization, we will employ a backward Euler scheme:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\int_{\\Omega}\\hat{K}(\\hat{h}^{n+1})^{-1} {\\bm{\\hat{u}}^{n+1}} \\cdot \\bm{v} \\, d\\Omega - \\int_{\\Omega} h^{n+1} \\hat{\\nabla} \\cdot {\\hat{\\bm{v}}} \\, d\\Omega = - \\int_{\\Gamma_D} h^{n+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega - \\int_{\\Gamma} \\eta^{n+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega\\\\\n",
    "\\int_{\\Omega} \\hat{S}_s^{n+1} \\frac{\\hat{h}^{n+1} - \\hat{h}^{n}}{\\Delta t} v \\, d\\Omega + \\int_{\\Omega} \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}^{n+1}} v \\, d\\Omega = \\int_{\\Omega} f^{n+1}v \\, d\\Omega\\\\\n",
    "\\int_{\\Gamma} \\phi \\eta^{n+1} v \\, d\\sigma = \\Delta t \\int_{\\Gamma} \\hat{\\bm{u}}^{n+1} \\cdot \\bm{\\nu} v \\, d\\sigma + \\int_{\\Gamma} \\phi \\eta^{n} v \\, d\\sigma + \\Delta t \\int_{\\Gamma} I^{n+1} v \\, d\\sigma\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf928a5",
   "metadata": {},
   "source": [
    "To deal with the non-linear term, we will employ a simple Picard scheme:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\int_{\\Omega}\\hat{K}(\\hat{h}^{n+1}_k)^{-1} {\\bm{\\hat{u}_{k+1}^{n+1}}} \\cdot \\bm{v} \\, d\\Omega - \\int_{\\Omega} h^{n+1}_{k+1} \\hat{\\nabla} \\cdot {\\hat{\\bm{v}}} \\, d\\Omega + \\int_{\\Gamma} \\eta^{n+1}_{k+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega= - \\int_{\\Gamma_D} h^{n+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega\\\\\n",
    "\\Delta t \\int_{\\Omega} \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}^{n+1}_{k+1}} v \\, d\\Omega + \\int_{\\Omega} \\hat{S}_s \\hat{h}^{n+1}_{k+1} v \\, d\\Omega = \\int_{\\Omega} \\hat{S}_s \\hat{h}^{n} v \\, d\\Omega + \\Delta t \\int_{\\Omega} f^{n+1}v \\, d\\Omega\\\\\n",
    "- \\Delta t \\int_{\\Gamma} \\hat{\\bm{u}}^{n+1}_{k+1} \\cdot \\bm{\\nu} v \\, d\\sigma + \\int_{\\Gamma} \\phi \\eta^{n+1}_{k+1} v \\, d\\sigma = \\int_{\\Gamma} \\phi \\eta^{n} v \\, d\\sigma + \\Delta t \\int_{\\Gamma} I^{n+1} v \\, d\\sigma\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615fb33d",
   "metadata": {},
   "source": [
    "The matrix formulation will be:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "M_u(\\bm{h}^{n+1}_{k+1}) \\bm{u}^{n+1}_{k+1} + B^T\\bm{h}^{n+1}_{k+1} + B_{\\Gamma} \\bm{\\eta}^{n+1}_{k+1}= \\bm{BC}^{n+1}\\\\\n",
    "- \\Delta t B \\hat{\\bm{u}}^{n+1}_{k+1} + S_s M_{h} \\bm{\\hat{h}^{n+1}_{k+1}} = \\Delta t \\bm{F}^{n+1} + S_s M_{h} \\bm{\\hat{h}^{n}}\\\\\n",
    "- \\Delta t B_{\\Gamma}^T \\hat{\\bm{u}}^{n+1}_{k+1} + \\phi M_{\\Gamma} \\bm{\\eta^{n+1}_{k+1}} = \\phi M_{\\Gamma} \\bm{\\eta^{n}} + \\Delta t \\bm{I}^{n+1}\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e31d3b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\n",
    "\\begin{array}{cc} \n",
    "M_u(\\bm{h^{n+1}_k}) & B^T & B_{\\Gamma}\\\\\n",
    "-\\Delta t B & S_s M_h & 0\\\\\n",
    "-\\Delta t B^T_{\\Gamma} & 0 & \\phi M_{\\Gamma}\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{u^{n+1}_{k+1}}\\\\ \n",
    "\\bm{h^{n+1}_{k+1}}\\\\\n",
    "\\bm{\\eta^{n+1}_{k+1}}\n",
    "\\end{array}\n",
    "\\right)\n",
    "=\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{BC}^{n+1}\\\\ \n",
    "\\Delta t \\bm{F}^{n+1} + S_s M_h \\bm{h}^n\\\\\n",
    "\\phi M_{\\Gamma} \\bm{\\eta}^n + \\Delta t \\bm{I}^{n+1}\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60777fa8",
   "metadata": {},
   "source": [
    "We will start to test the method in the case $M_u(\\bm{h_k}^{n+1})=\\bm{I}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dietary-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from math import ceil, floor, log10, exp, isnan\n",
    "import os, shutil\n",
    "\n",
    "import porepy as pp\n",
    "import pygeon as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1342bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-glossary",
   "metadata": {},
   "source": [
    "We create now the grid, since we will use a Raviart-Thomas approximation for ${q}$ we are restricted to simplices. In this example we consider a 2-dimensional structured grid, but the presented code will work also in 1d and 3d. PyGeoN works with mixed-dimensional grids, so we need to convert the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0816cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "T = 10\n",
    "S_s = 0.3\n",
    "phi = 0.1\n",
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c363e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_tol = 1e-6\n",
    "rel_tol = 1e-6\n",
    "max_iterations_per_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spectacular-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the grid into a mixed-dimensional grid\n",
    "sd = pp.StructuredTriangleGrid([N, N], [1, 1])\n",
    "sd.compute_geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa231fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_grid, boundary_face_map, boundary_node_map = pp.partition.extract_subgrid(sd, sd.face_centers[1, :] == 1, faces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb80af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg = pp.meshing.subdomains_to_mdg([sd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-belle",
   "metadata": {},
   "source": [
    "With the following code we set the data, in particular the permeability tensor and the boundary conditions. Since we need to identify each side of $\\partial \\Omega$ we need few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spare-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"flow\"\n",
    "\n",
    "darcy_data = {}\n",
    "richards_data = {}\n",
    "\n",
    "bc_val = []\n",
    "bc_ess = []\n",
    "initial_pressure = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd8b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_discretization_field = pg.RT0(key)\n",
    "boundary_discretization_field = pg.Lagrange1(key)\n",
    "head_discretization_field     = pg.PwConstants(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e5c3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdomain, data = mdg.subdomains(return_data=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6fa7931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discretization_matrices': {'flow': {}},\n",
       " 'parameters': Data object for physical processes flow\n",
       " The keyword \"flow\" has the following parameters specified: second_order_tensor}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.initialize_data(subdomain, data, key, {\n",
    "    \"second_order_tensor\": pp.SecondOrderTensor(np.ones(subdomain.num_cells)),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f7432b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual BC (no slip on the left and right, fixed unitary head on the bottom. No condition on the top boundary)\n",
    "left_right = np.logical_or(sd.face_centers[0, :] == 0,  sd.face_centers[0, :] == 1)\n",
    "\n",
    "bottom = sd.face_centers[1, :] == 0\n",
    "\n",
    "ess_p_dofs = np.zeros(head_discretization_field.ndof(sd), dtype=bool)\n",
    "\n",
    "def h_bc(x): return 1\n",
    "def initial_h_func(x): return 1\n",
    "def infiltration(x): return 1e-3\n",
    "\n",
    "bc_val.append(-velocity_discretization_field.assemble_nat_bc(sd, h_bc, bottom))\n",
    "bc_ess.append(np.hstack((left_right, ess_p_dofs, np.zeros(N+1, dtype=bool))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30f6e9",
   "metadata": {},
   "source": [
    "The $RT_0$ elements are constructed in such a wat that, on the non-diagonal faces, $\\bm{v} \\cdot \\nu = 0$. Then, since $\\Gamma$ is made by one of the two catheti of each boundary facing element, the only non-zero terms will be associated to the basis functions associated to the ``boundary'' cathetus. Then:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017a58d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix} -x \\\\ -y \\end{bmatrix} \\cdot \\begin{bmatrix}-1 \\\\ 0 \\end{bmatrix} = 0 \\text{ on } \\Gamma\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5715f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix} -x \\\\ 1-y \\end{bmatrix} \\cdot \\begin{bmatrix}-1 \\\\ 0 \\end{bmatrix} = 0 \\text{ on } \\Gamma\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db926ed",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix} x-1 \\\\ y \\end{bmatrix} \\cdot \\begin{bmatrix}-1 \\\\ 0 \\end{bmatrix} \\neq 0 \\text{ on } \\Gamma\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b9875",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int_0^1 \\left| \\bm{x}_1 - \\bm{x}_0 \\right| \\begin{bmatrix} -1 \\\\ s \\end{bmatrix} \\cdot \\begin{bmatrix}-1 \\\\ 0 \\end{bmatrix} s ds = \\int_0^1 \\left| \\bm{x}_1 - \\bm{x}_0 \\right| \\begin{bmatrix} -1 \\\\ s \\end{bmatrix} \\cdot \\begin{bmatrix}-1 \\\\ 0 \\end{bmatrix} (1-s) ds = \\frac{\\left| \\bm{x}_1 - \\bm{x}_0 \\right|}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aee36a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_B_gamma():\n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "\n",
    "    # Take the x-coordinate of each face center\n",
    "    faces_center_pos = sd.face_centers[0,:]\n",
    "\n",
    "    # Look for the boundary faces ids\n",
    "    index_up_face = np.where(sd.face_centers[1, :] == 1)[0]\n",
    "\n",
    "    # Loop thorough the boundary faces\n",
    "    for i in range(N):\n",
    "        # s-element\n",
    "        col.append(index_up_face[i])\n",
    "        row.append(i)\n",
    "        data.append( np.abs(faces_center_pos[i] - faces_center_pos[i+1]) / 2 )\n",
    "        \n",
    "        # (1-s)-element\n",
    "        col.append(index_up_face[i])\n",
    "        row.append(i+1)\n",
    "        data.append( np.abs(faces_center_pos[i] - faces_center_pos[i+1]) / 2 )\n",
    "    \n",
    "    return sps.coo_matrix( (data, (row, col)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc2f1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_gamma = assemble_B_gamma()\n",
    "M_gamma = boundary_discretization_field.assemble_mass_matrix( boundary_grid )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b6345",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\n",
    "\\begin{array}{cc} \n",
    "M_u(\\bm{h^{n+1}_k}, \\bm{\\eta_k^{n+1}}) & B^T & B_{\\Gamma}\\\\\n",
    "-\\Delta t B & S_s M_h & 0\\\\\n",
    "-\\Delta t B^T_{\\Gamma} & 0 & \\phi M_{\\Gamma}\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{u^{n+1}_{k+1}}\\\\ \n",
    "\\bm{h^{n+1}_{k+1}}\\\\\n",
    "\\bm{\\eta^{n+1}_{k+1}}\n",
    "\\end{array}\n",
    "\\right)\n",
    "=\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{BC}^{n+1}\\\\ \n",
    "\\Delta t \\bm{F}^{n+1} + S_s M_h \\bm{h}^n\\\\\n",
    "\\phi M_{\\Gamma} \\bm{\\eta}^n + \\Delta t \\bm{I}^{n+1}\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74185040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 85), (6, 85))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B matrix\n",
    "div = - pg.cell_mass(mdg, head_discretization_field) @ pg.div(mdg)\n",
    "\n",
    "dof_p, dof_q = div.shape\n",
    "dof_eta = B_gamma.shape[0]\n",
    "\n",
    "div.shape, B_gamma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf327d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed rhs\n",
    "fixex_rhs = np.zeros(dof_p + dof_q + dof_eta)\n",
    "fixex_rhs[:dof_q] += np.hstack(bc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "551da31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to save the given solution to a VTU file\n",
    "def save_step(sol, proj_q, proj_psi, proj_eta, saver, i):\n",
    "    ins = list()\n",
    "\n",
    "    ins.append((sd, \"cell_q\", ( proj_q @ sol[-1][:dof_q] ).reshape((3, -1), order=\"F\")))\n",
    "    ins.append((sd, \"cell_h\", proj_psi @ sol[-1][dof_q:(dof_q+dof_p)]))\n",
    "    #ins.append((boundary_grid, \"cell_eta\", proj_eta @ sol[-1][-dof_eta:]))\n",
    "    print( proj_eta @ sol[-1][-dof_eta:] )\n",
    "\n",
    "    saver.write_vtu(ins, time_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd1d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_directory):\n",
    "    shutil.rmtree(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88812b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions\n",
    "sol = [np.zeros(dof_p + dof_q + dof_eta)]\n",
    "sol[-1][dof_q:(dof_q+dof_p)] = head_discretization_field.interpolate(sd, initial_h_func)\n",
    "sol[-1][-dof_eta:] = np.ones_like(sol[-1][-dof_eta:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cfd1a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Prepare helper matrices\n",
    "\n",
    "proj_q = velocity_discretization_field.eval_at_cell_centers(sd)\n",
    "proj_psi = head_discretization_field.eval_at_cell_centers(sd)\n",
    "proj_eta = boundary_discretization_field.eval_at_cell_centers(boundary_grid)\n",
    "\n",
    "eta_diff = boundary_discretization_field.assemble_diff_matrix(boundary_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial solution\n",
    "\n",
    "saver = pp.Exporter(mdg, 'sol', folder_name=output_directory)\n",
    "save_step(sol, proj_q, proj_psi, proj_eta, saver, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e05b3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[pp.PARAMETERS][key].update({\"second_order_tensor\": pp.SecondOrderTensor(np.ones(subdomain.num_cells))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6036f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #001, error L2 relative psi:    0.5856488884\n",
      "Iteration #002, error L2 relative psi:    0.2105297510\n",
      "Iteration #003, error L2 relative psi:    0.0992666596\n",
      "Iteration #004, error L2 relative psi:    0.0531918511\n",
      "Iteration #005, error L2 relative psi:    0.0368818740\n",
      "Iteration #006, error L2 relative psi:    0.0306273947\n",
      "Iteration #007, error L2 relative psi:    0.0279741703\n",
      "Iteration #008, error L2 relative psi:    0.0273463412\n",
      "Iteration #009, error L2 relative psi:    0.0285243766\n",
      "Iteration #010, error L2 relative psi:    0.0319178353\n",
      "Iteration #011, error L2 relative psi:    0.0387749851\n",
      "Iteration #012, error L2 relative psi:    0.0523269841\n",
      "Iteration #013, error L2 relative psi:    0.0822162049\n",
      "Iteration #014, error L2 relative psi:    0.1691097371\n",
      "Iteration #015, error L2 relative psi:    0.7546858191\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor is not positive definite because of components in y-direction",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/richards/tests/coupling_test/simple_moving_darcy/darcy.ipynb Cell 33\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6661636375735c5c7269636861726473222c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6661636375732f72696368617264732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/richards/tests/coupling_test/simple_moving_darcy/darcy.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     kyy[c] \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mpower(x_center[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m grad_eta[eta_cell], \u001b[39m2\u001b[39m)) \u001b[39m/\u001b[39m center_eta[eta_cell]\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6661636375735c5c7269636861726473222c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6661636375732f72696368617264732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/richards/tests/coupling_test/simple_moving_darcy/darcy.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m _, data \u001b[39m=\u001b[39m mdg\u001b[39m.\u001b[39msubdomains(return_data\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6661636375735c5c7269636861726473222c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6661636375732f72696368617264732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/richards/tests/coupling_test/simple_moving_darcy/darcy.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m data[pp\u001b[39m.\u001b[39mPARAMETERS][key]\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39msecond_order_tensor\u001b[39m\u001b[39m\"\u001b[39m: pp\u001b[39m.\u001b[39;49mSecondOrderTensor(kxx\u001b[39m=\u001b[39;49mkxx, kyy\u001b[39m=\u001b[39;49mkyy, kxy\u001b[39m=\u001b[39;49mkxy)})\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6661636375735c5c7269636861726473222c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6661636375732f72696368617264732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/richards/tests/coupling_test/simple_moving_darcy/darcy.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m mass \u001b[39m=\u001b[39m pg\u001b[39m.\u001b[39mface_mass(mdg, velocity_discretization_field)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6661636375735c5c7269636861726473222c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6661636375732f72696368617264732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/richards/tests/coupling_test/simple_moving_darcy/darcy.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# assemble the saddle point problem\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/porepy/params/tensor.py:68\u001b[0m, in \u001b[0;36mSecondOrderTensor.__init__\u001b[0;34m(self, kxx, kyy, kzz, kxy, kxz, kyz)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m# Onsager's principle - tensor should be positive definite\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many((kxx \u001b[39m*\u001b[39m kyy \u001b[39m-\u001b[39m kxy \u001b[39m*\u001b[39m kxy) \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTensor is not positive definite because of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcomponents in y-direction\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     73\u001b[0m perm[\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, ::] \u001b[39m=\u001b[39m kxy\n\u001b[1;32m     74\u001b[0m perm[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, ::] \u001b[39m=\u001b[39m kxy\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor is not positive definite because of components in y-direction"
     ]
    }
   ],
   "source": [
    "# Time Loop\n",
    "for i in range(1, int(T/dt)+1):\n",
    "    # Prepare the solution at the previous time step and ...\n",
    "    prev = sol[-1].copy()    \n",
    "    # prepare the rhs\n",
    "    rhs = fixex_rhs.copy()\n",
    "    rhs[dof_q:(dof_q+dof_p)] += S_s / dt * head_discretization_field.assemble_mass_matrix(sd) @ prev[dof_q:(dof_q+dof_p)]\n",
    "    rhs[-dof_eta:] += (phi / dt * M_gamma @ prev[-dof_eta:] + M_gamma @ boundary_discretization_field.interpolate(boundary_grid, infiltration))\n",
    "    \n",
    "    # Non-linear loop\n",
    "    for k in range(max_iterations_per_step):\n",
    "        \n",
    "        # Prepare the conductivity\n",
    "        kxx = np.zeros(shape=(sd.num_cells,))\n",
    "        kyy = np.zeros(shape=(sd.num_cells,))\n",
    "        kxy = np.zeros(shape=(sd.num_cells,))\n",
    "\n",
    "        # Gradient of eta and pointwise value\n",
    "        grad_eta = eta_diff @ prev[-dof_eta:]\n",
    "        center_eta = proj_eta @ prev[-dof_eta:]\n",
    "        \n",
    "        # \"Dumb\" K preparation\n",
    "        for c in np.arange(sd.num_cells):\n",
    "            x_center = sd.cell_centers[:, c]\n",
    "            \n",
    "            eta_cell = np.max(np.where( boundary_grid.nodes[0, :] < x_center[0] ))\n",
    "\n",
    "            kxx[c] = x_center[1]\n",
    "            kxy[c] = -x_center[1] * grad_eta[eta_cell]\n",
    "            kyy[c] = (1 + np.power(x_center[1] * grad_eta[eta_cell], 2)) / center_eta[eta_cell]\n",
    "\n",
    "        _, data = mdg.subdomains(return_data=True)[0]\n",
    "\n",
    "        # Update conductivity and generate mass with conductivity\n",
    "        data[pp.PARAMETERS][key].update({\"second_order_tensor\": pp.SecondOrderTensor(kxx=kxx, kyy=kyy, kxy=kxy)})\n",
    "        mass = pg.face_mass(mdg, velocity_discretization_field)\n",
    "\n",
    "        # Assemble the saddle point problem\n",
    "        spp = sps.bmat([[    mass,                                                         div.T,          B_gamma.T], \n",
    "                        [    -div, S_s / dt * head_discretization_field.assemble_mass_matrix(sd),               None],\n",
    "                        [-B_gamma,                                                          None, phi / dt * M_gamma]], format=\"csc\")\n",
    "        \n",
    "        # Prepare the solver\n",
    "        ls = pg.LinearSystem(spp, rhs)\n",
    "        ls.flag_ess_bc(np.hstack(bc_ess), np.zeros(dof_q + dof_p + dof_eta))\n",
    "\n",
    "        current = ls.solve()\n",
    "\n",
    "        #print(current[dof_q:])\n",
    "\n",
    "        # Compute the errors (with eta). Should I consider only psi? Should I compute the error on the \"actual\" psi values or on the dofs\n",
    "        abs_err_psi  = np.sqrt(np.sum(np.power(current[dof_q:] - prev[dof_q:], 2)))\n",
    "        abs_err_prev = np.sqrt(np.sum(np.power(prev[dof_q:], 2)))\n",
    "\n",
    "        print('Iteration #' + format(k+1, '0' + str(ceil(log10(max_iterations_per_step)) + 1) + 'd') \n",
    "              + ', error L2 relative psi: ' + format(abs_err_psi, str(5 + ceil(log10(1 / abs_tol)) + 4) \n",
    "                                                     + '.' + str(ceil(log10(1 / abs_tol)) + 4) + 'f') )\n",
    "\n",
    "        if abs_err_psi < abs_tol + rel_tol * abs_err_prev:\n",
    "            break\n",
    "        else:\n",
    "            prev = None\n",
    "            prev = current.copy()\n",
    "\n",
    "    print('')        \n",
    "\n",
    "    sol.append( current.copy() )\n",
    "\n",
    "    save_step(sol, proj_q, proj_psi, proj_eta, saver, i)\n",
    "\n",
    "saver.write_pvd([t * dt for t in range(int(T/dt)+1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cc1db98167c7fd7d55a1da8057731abc6cd6fe154328a2ae319df8aab4e24d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
