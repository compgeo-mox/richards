{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "essential-american",
   "metadata": {},
   "source": [
    "# Darcy equation\n",
    "\n",
    "In this tutorial we present how to solve a Darcy equation with [PyGeoN](https://github.com/compgeo-mox/pygeon) in themoving domain case (the upper boundary will move).  The unkwons are the velocity $u$, the elevation head $h$ and the height of the upper boundary $\\eta$.\n",
    "\n",
    "Let $\\Omega=(0,1)\\times(0,\\eta)$ with boundary $\\partial \\Omega$ and outward unit normal ${\\nu}$. Given \n",
    "$K$ the matrix permeability, we want to solve the following problem: find $(\\bm{u}, h)$ such that\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "K^{-1} {\\bm{u}} + \\nabla h = {0}\\\\\n",
    "S_s \\frac{\\partial{h}}{\\partial t} + \\nabla \\cdot {u} = f\n",
    "\\end{array}\n",
    "&\\text{in } \\Omega\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbb451",
   "metadata": {},
   "source": [
    "In order to solve the problem, we will perfom a change of coordinates to a reference domain $\\hat{\\Omega}=(0,1)^2$ through the (linear) trasnformation $R : \\Omega \\rightarrow \\hat{\\Omega}$ (and its inverse function $D : \\hat{\\Omega} \\rightarrow \\Omega$).\n",
    "Recall that $\\hat{\\nabla}R=(\\nabla D)^{-1}$.\n",
    "\n",
    "Let $\\hat{h}$ and $\\hat{\\bm{u}}$ be $h$ and $\\bm{u}$ respectevely in the reference domain and let $\\hat{K}$ be the transformed permeability matrix, defined as $\\hat{K}=det(\\hat{\\nabla}D) (\\hat{\\nabla} D)^{-1} K (\\hat{\\nabla} D)^{-T}$.\n",
    "\n",
    "The equation describing the motion of $\\partial_{top}\\Omega$ is:\n",
    "$$\n",
    "\n",
    "\\phi \\frac{\\partial \\eta}{\\partial t} = \\hat{u_3} + I(t)\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068fac3",
   "metadata": {},
   "source": [
    "The transformed equations in $\\hat{\\Omega}$ is:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\hat{K}({\\eta})^{-1} {\\hat{u}} + \\hat{\\nabla} \\hat{h} = {0}\\\\\n",
    "\\hat{S}_s \\frac{\\partial{\\hat{h}}}{\\partial t} + \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}} = f\n",
    "\\end{array}\n",
    "&\\text{in } \\hat{\\Omega}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "with boundary conditions:\n",
    "$$ \\hat{h} = \\eta \\text{ on } \\Gamma \\qquad \\hat{h} = \\ell \\text{ on } \\Gamma_D \\qquad \\hat{\\bm{\\nu}} \\cdot \\hat{\\bm{u}} = 0 \\text{ on } \\Gamma_N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b01879",
   "metadata": {},
   "source": [
    "The weak formulation will be:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\int_{\\Omega}\\hat{K}(\\eta)^{-1} {\\bm{\\hat{u}}} \\cdot \\bm{v} \\, d\\Omega - \\int_{\\Omega} h \\hat{\\nabla} \\cdot {\\hat{\\bm{v}}} \\, d\\Omega = - \\int_{\\Gamma_D} h \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega - \\int_{\\Gamma} \\eta \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega\\\\\n",
    "\\int_{\\Omega} \\hat{S}_s \\frac{\\partial{\\hat{h}}}{\\partial t} v \\, d\\Omega + \\int_{\\Omega} \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}} v \\, d\\Omega = \\int_{\\Omega} fv \\, d\\Omega\\\\\n",
    "\\int_{\\Gamma} \\phi \\frac{\\partial \\eta}{\\partial t} v \\, d\\sigma = \\int_{\\Gamma} \\hat{u_3} v \\, d\\sigma + \\int_{\\Gamma} I(t) v \\, d\\sigma\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc7603",
   "metadata": {},
   "source": [
    "For the time discretization, we will employ a backward Euler scheme:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\int_{\\Omega}\\hat{K}(\\eta^{n+1})^{-1} {\\bm{\\hat{u}}^{n+1}} \\cdot \\bm{v} \\, d\\Omega - \\int_{\\Omega} h^{n+1} \\hat{\\nabla} \\cdot {\\hat{\\bm{v}}} \\, d\\Omega = - \\int_{\\Gamma_D} h^{n+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega - \\int_{\\Gamma} \\eta^{n+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega\\\\\n",
    "\\int_{\\Omega} \\hat{S}_s^{n+1} \\frac{\\hat{h}^{n+1} - \\hat{h}^{n}}{\\Delta t} v \\, d\\Omega + \\int_{\\Omega} \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}^{n+1}} v \\, d\\Omega = \\int_{\\Omega} f^{n+1}v \\, d\\Omega\\\\\n",
    "\\int_{\\Gamma} \\phi \\eta^{n+1} v \\, d\\sigma = \\Delta t \\int_{\\Gamma} \\hat{\\bm{u}}^{n+1} \\cdot \\bm{\\nu} v \\, d\\sigma + \\int_{\\Gamma} \\phi \\eta^{n} v \\, d\\sigma + \\Delta t \\int_{\\Gamma} I^{n+1} v \\, d\\sigma\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf928a5",
   "metadata": {},
   "source": [
    "To deal with the non-linear term, we will employ a simple Picard scheme:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "\\int_{\\Omega}\\hat{K}(\\eta^{n+1}_k)^{-1} {\\bm{\\hat{u}_{k+1}^{n+1}}} \\cdot \\bm{v} \\, d\\Omega - \\int_{\\Omega} h^{n+1}_{k+1} \\hat{\\nabla} \\cdot {\\hat{\\bm{v}}} \\, d\\Omega + \\int_{\\Gamma} \\eta^{n+1}_{k+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega= - \\int_{\\Gamma_D} h^{n+1} \\bm{v} \\cdot \\bm{\\nu} \\, d\\Omega\\\\\n",
    "\\Delta t \\int_{\\Omega} \\hat{\\nabla} \\cdot {\\hat{\\bm{u}}^{n+1}_{k+1}} v \\, d\\Omega + \\int_{\\Omega} \\hat{S}_s \\hat{h}^{n+1}_{k+1} v \\, d\\Omega = \\int_{\\Omega} \\hat{S}_s \\hat{h}^{n} v \\, d\\Omega + \\Delta t \\int_{\\Omega} f^{n+1}v \\, d\\Omega\\\\\n",
    "- \\Delta t \\int_{\\Gamma} \\hat{\\bm{u}}^{n+1}_{k+1} \\cdot \\bm{\\nu} v \\, d\\sigma + \\int_{\\Gamma} \\phi \\eta^{n+1}_{k+1} v \\, d\\sigma = \\int_{\\Gamma} \\phi \\eta^{n} v \\, d\\sigma + \\Delta t \\int_{\\Gamma} I^{n+1} v \\, d\\sigma\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615fb33d",
   "metadata": {},
   "source": [
    "The matrix formulation will be:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\begin{array}{l} \n",
    "M_u(\\bm{\\eta}^{n+1}_{k}) \\bm{u}^{n+1}_{k+1} + B^T\\bm{h}^{n+1}_{k+1} + B_{\\Gamma}^T \\bm{\\eta}^{n+1}_{k+1}= \\bm{BC}^{n+1}\\\\\n",
    "- \\Delta t B \\hat{\\bm{u}}^{n+1}_{k+1} + S_s M_{h} \\bm{\\hat{h}^{n+1}_{k+1}} = \\Delta t \\bm{F}^{n+1} + S_s M_{h} \\bm{\\hat{h}^{n}}\\\\\n",
    "- \\Delta t B_{\\Gamma} \\hat{\\bm{u}}^{n+1}_{k+1} + \\phi M_{\\Gamma} \\bm{\\eta^{n+1}_{k+1}} = \\phi M_{\\Gamma} \\bm{\\eta^{n}} + \\Delta t \\bm{I}^{n+1}\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e31d3b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\n",
    "\\begin{array}{cc} \n",
    "M_u(\\bm{\\eta^{n+1}_k}) & B^T & B_{\\Gamma}^T\\\\\n",
    "-\\Delta t B & S_s M_h & 0\\\\\n",
    "-\\Delta t B_{\\Gamma} & 0 & \\phi M_{\\Gamma}\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{u^{n+1}_{k+1}}\\\\ \n",
    "\\bm{h^{n+1}_{k+1}}\\\\\n",
    "\\bm{\\eta^{n+1}_{k+1}}\n",
    "\\end{array}\n",
    "\\right)\n",
    "=\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{BC}^{n+1}\\\\ \n",
    "\\Delta t \\bm{F}^{n+1} + S_s M_h \\bm{h}^n\\\\\n",
    "\\phi M_{\\Gamma} \\bm{\\eta}^n + \\Delta t \\bm{I}^{n+1}\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60777fa8",
   "metadata": {},
   "source": [
    "We will start to test the method in the case $M_u(\\bm{h_k}^{n+1})=\\bm{I}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa691294",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dietary-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/porepy/numerics/nonlinear/nonlinear_solvers.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from math import ceil, floor, log10, exp, isnan\n",
    "import os, shutil\n",
    "\n",
    "import porepy as pp\n",
    "import pygeon as pg\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1342bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'output_std'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-glossary",
   "metadata": {},
   "source": [
    "We create now the grid, since we will use a Raviart-Thomas approximation for ${q}$ we are restricted to simplices. In this example we consider a 2-dimensional structured grid, but the presented code will work also in 1d and 3d. PyGeoN works with mixed-dimensional grids, so we need to convert the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0816cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "T = 1\n",
    "S_s = 0\n",
    "phi = 0.1\n",
    "\n",
    "stab = 0\n",
    "\n",
    "N = 40 # 16\n",
    "quad_order = 5\n",
    "\n",
    "\n",
    "infiltration_rate = 1e-3\n",
    "extraction_rate = -0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c363e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_tol = 1e-6\n",
    "rel_tol = 1e-6\n",
    "max_iterations_per_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spectacular-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the grid into a mixed-dimensional grid\n",
    "sd = pp.StructuredTriangleGrid([N, N], [1, 1])\n",
    "sd.compute_geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa231fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_grid, boundary_face_map, boundary_node_map = pp.partition.extract_subgrid(sd, sd.face_centers[1, :] == 1, faces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb80af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg = pp.meshing.subdomains_to_mdg([sd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-belle",
   "metadata": {},
   "source": [
    "With the following code we set the data, in particular the permeability tensor and the boundary conditions. Since we need to identify each side of $\\partial \\Omega$ we need few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spare-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"flow\"\n",
    "\n",
    "darcy_data = {}\n",
    "richards_data = {}\n",
    "\n",
    "bc_val = []\n",
    "bc_ess_flag = []\n",
    "initial_pressure = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd8b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_field     = pg.RT0(key)\n",
    "gamma_field = pg.Lagrange1(key)\n",
    "h_field     = pg.PwConstants(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e5c3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdomain, data = mdg.subdomains(return_data=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9103404",
   "metadata": {},
   "outputs": [],
   "source": [
    "dof_q   = q_field.ndof( subdomain )\n",
    "dof_p   = h_field.ndof( subdomain )\n",
    "dof_eta = gamma_field.ndof( boundary_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6fa7931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discretization_matrices': {'flow': {}},\n",
       " 'parameters': Data object for physical processes flow\n",
       " The keyword \"flow\" has the following parameters specified: second_order_tensor}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.initialize_data(subdomain, data, key, {\n",
    "    \"second_order_tensor\": pp.SecondOrderTensor(np.ones(subdomain.num_cells)),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dac4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_bc_ess_val():\n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "\n",
    "    face, _, sign = sps.find(subdomain.cell_faces)\n",
    "\n",
    "    face_ids = np.where(sd.face_centers[0, :] == 0)[0]\n",
    "\n",
    "    for face_id in face_ids:\n",
    "        s = -sign[ np.where(face == face_id) ][0]\n",
    "\n",
    "        row.append(face_id)\n",
    "        col.append(0)\n",
    "        data.append( s * extraction_rate / N )\n",
    "\n",
    "    res = sps.coo_array( (data, (row, col)), shape=(dof_q + dof_p + dof_eta, 1) ).todense().flatten()\n",
    "    \n",
    "    return (lambda t: res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f7432b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual BC (no slip on the left and right, fixed unitary head on the bottom. No condition on the top boundary)\n",
    "left = sd.face_centers[0, :] == 0\n",
    "right = sd.face_centers[0, :] == 1\n",
    "\n",
    "bottom = sd.face_centers[1, :] == 0\n",
    "\n",
    "ess_p_dofs = np.zeros(h_field.ndof(sd), dtype=bool)\n",
    "\n",
    "def h_bc(x, t): return 1\n",
    "def initial_h_func(x): return 1\n",
    "def infiltration(x, t): return infiltration_rate\n",
    "\n",
    "bc_val = lambda t: -q_field.assemble_nat_bc(sd, lambda x: h_bc(x,t), right)\n",
    "bc_ess_flag = lambda t: np.hstack((np.logical_or(bottom, left), ess_p_dofs, np.zeros(boundary_grid.num_nodes, dtype=bool)))\n",
    "bc_ess_val  = assemble_bc_ess_val()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30f6e9",
   "metadata": {},
   "source": [
    "The $RT_0$ elements are constructed in such a wat that, on the non-diagonal faces, $\\bm{v} \\cdot \\nu = 0$. Then, since $\\Gamma$ is made by one of the two catheti of each boundary facing element, the only non-zero terms will be associated to the basis functions associated to the ``boundary'' cathetus. Then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aee36a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_B_gamma():\n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "\n",
    "    face, _, sign = sps.find(subdomain.cell_faces)\n",
    "\n",
    "    # Look for the boundary faces ids\n",
    "    index_up_face = np.where(sd.face_centers[1, :] == 1)[0]\n",
    "\n",
    "    # Loop thorough the boundary faces\n",
    "    for i in range( boundary_grid.num_cells ):\n",
    "        s = sign[ np.where(face == index_up_face[i]) ][0]\n",
    "\n",
    "        # s-element\n",
    "        col.append(index_up_face[i])\n",
    "        row.append(i)\n",
    "        data.append( s / 2 )\n",
    "\n",
    "        # (1-s)-element\n",
    "        col.append(index_up_face[i])\n",
    "        row.append(i+1)\n",
    "        data.append( s / 2 )\n",
    "    \n",
    "    return sps.coo_matrix( (data, (row, col)), shape=(N+1, sd.num_faces) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84c3ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_diff = gamma_field.assemble_diff_matrix(boundary_grid)\n",
    "eta_diff[0,0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc2f1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_gamma = assemble_B_gamma()\n",
    "M_gamma = gamma_field.assemble_mass_matrix( boundary_grid )\n",
    "A_gamma = eta_diff.T @ eta_diff / N\n",
    "\n",
    "M_h = h_field.assemble_mass_matrix( subdomain )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b6345",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\n",
    "\\begin{array}{cc} \n",
    "M_u(\\bm{\\eta_k^{n+1}}) & B^T & B_{\\Gamma}^T\\\\\n",
    "-\\Delta t B & S_s M_h & 0\\\\\n",
    "-\\Delta t B_{\\Gamma} & 0 & \\phi M_{\\Gamma}\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{u^{n+1}_{k+1}}\\\\ \n",
    "\\bm{h^{n+1}_{k+1}}\\\\\n",
    "\\bm{\\eta^{n+1}_{k+1}}\n",
    "\\end{array}\n",
    "\\right)\n",
    "=\\left(\n",
    "\\begin{array}{c} \n",
    "\\bm{BC}^{n+1}\\\\ \n",
    "\\Delta t \\bm{F}^{n+1} + S_s M_h \\bm{h}^n\\\\\n",
    "\\phi M_{\\Gamma} \\bm{\\eta}^n + \\Delta t \\bm{I}^{n+1}\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74185040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 4880), (41, 4880))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B matrix\n",
    "B = - pg.cell_mass(mdg, h_field) @ pg.div(mdg)\n",
    "\n",
    "B.shape, B_gamma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3283a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_projection_matrix():\n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "\n",
    "    for c in range(subdomain.num_cells):\n",
    "        x_center = subdomain.cell_centers[:, c]\n",
    "        id = np.max(np.where( boundary_grid.nodes[0, :] < x_center[0] ))\n",
    "\n",
    "        data.append(1)\n",
    "        row.append(c)\n",
    "        col.append(id)\n",
    "\n",
    "    return sps.coo_matrix( (data, (row, col)), shape=(subdomain.num_cells, boundary_grid.num_cells) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "551da31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_proj_eta = vertical_projection_matrix()\n",
    "\n",
    "# Helper function to save the given solution to a VTU file\n",
    "def save_step(sol, proj_q, proj_psi, proj_eta, saver, i):\n",
    "    ins = list()\n",
    "\n",
    "    ins.append((sd, \"cell_q\", ( proj_q @ sol[:dof_q] ).reshape((3, -1), order=\"F\")))\n",
    "    ins.append((sd, \"cell_h\", proj_psi @ sol[dof_q:(dof_q+dof_p)]))\n",
    "    ins.append((sd, \"cell_eta\", cell_proj_eta @ proj_eta @ sol[-dof_eta:]))\n",
    "\n",
    "    saver.write_vtu(ins, time_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cd1d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_directory):\n",
    "    shutil.rmtree(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d88812b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions\n",
    "\n",
    "sol = [np.zeros(dof_p + dof_q + dof_eta)]\n",
    "sol[-1][dof_q:(dof_q+dof_p)] = h_field.interpolate(sd, initial_h_func)\n",
    "sol[-1][-dof_eta:] = gamma_field.interpolate(boundary_grid, lambda x: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cfd1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare helper matrices\n",
    "\n",
    "proj_q = q_field.eval_at_cell_centers(sd)\n",
    "proj_psi = h_field.eval_at_cell_centers(sd)\n",
    "proj_eta = gamma_field.eval_at_cell_centers(boundary_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7b9af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial solution\n",
    "\n",
    "saver = pp.Exporter(mdg, 'sol', folder_name=output_directory)\n",
    "save_step(sol[-1], proj_q, proj_psi, proj_eta, saver, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e05b3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[pp.PARAMETERS][key].update({\"second_order_tensor\": pp.SecondOrderTensor(np.ones(subdomain.num_cells))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d6460c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed rhs\n",
    "fixed_rhs = np.zeros(dof_p + dof_q + dof_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bac2e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "def q1(x: float, y: float):\n",
    "    return np.array([-x, -y])\n",
    "\n",
    "def q2(x: float, y: float):\n",
    "    return np.array([x-1, y])\n",
    "\n",
    "def q3(x: float, y: float):\n",
    "    return np.array([-x, 1-y])\n",
    "\n",
    "def find_ordering(coord: np.array):\n",
    "    lx = np.argmin(coord[0, :])\n",
    "    rx = np.argmax(coord[0, :])\n",
    "    mx = np.setdiff1d(np.array([0,1,2]), np.array([lx, rx]))[0]\n",
    "\n",
    "    # Vertical Alignment\n",
    "    if np.abs( coord[0, lx] - coord[0, mx] ) < 1 / (2 * N):\n",
    "        # lx and mx vertical aligned, rx no\n",
    "        up =   lx if np.argmax(coord[1, np.array([lx, mx])]) == 0 else mx\n",
    "        down = lx if np.argmin(coord[1, np.array([lx, mx])]) == 0 else mx\n",
    "\n",
    "        if np.abs( coord[1, up] - coord[1, rx] ) < 1 / (2 * N):\n",
    "            return [up, down, rx]\n",
    "        else:\n",
    "            return [down, rx, up]\n",
    "    else:\n",
    "        # rx and mx vertical aligned, lx no\n",
    "        up =   rx if np.argmax(coord[1, np.array([rx, mx])]) == 0 else mx\n",
    "        down = rx if np.argmin(coord[1, np.array([rx, mx])]) == 0 else mx\n",
    "\n",
    "        if np.abs( coord[1, up] - coord[1, lx] ) < 1 / (2 * N):\n",
    "            return [up, lx, down]\n",
    "        else:\n",
    "            return [down, up, lx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c214150",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "def K11(x: float, y: float):\n",
    "    return 4 if y>0.5 else 1\n",
    "\n",
    "def K22(x: float, y: float):\n",
    "    return 4 if y>0.5 else 1\n",
    "\n",
    "def K12(x: float, y: float):\n",
    "    return 0\n",
    "\n",
    "def K21(x: float, y: float):\n",
    "    return 0\n",
    "\n",
    "def K_func(base_height: float, element_height: float, m: int, ls_eta: float, rs_eta: float, grad_eta: float):\n",
    "    eta = lambda x,y: (1-((m+1) * (1-y) / 2 - (m-1) * y / 2)) * ls_eta + ((m+1) * (1-y) / 2 - (m-1) * y / 2) * rs_eta\n",
    "    x_3 = lambda x,y: base_height + (1-((m+1) * (1-x) / 2 - (m-1) * x / 2)) * element_height\n",
    "     \n",
    "    k11 = lambda x,y: ( K22(x,y) + x_3(x,y) * grad_eta * ( x_3(x,y) * grad_eta * K11(x,y) - K12(x,y) - K21(x,y) ) ) / eta(x,y)\n",
    "    k12 = lambda x,y: x_3(x,y) * grad_eta * K11(x,y) - K12(x,y)\n",
    "    k21 = lambda x,y: x_3(x,y) * grad_eta * K11(x,y) - K21(x,y)\n",
    "    k22 = lambda x,y: eta(x,y) * K11(x,y)\n",
    "\n",
    "    return lambda x,y: np.array([[k11(x,y), k12(x,y)],\n",
    "                                 [k21(x,y), k22(x,y)]]) / ( K11(x,y) * K22(x,y) - K12(x,y) * K21(x,y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0eb2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_q(coord, sign, ls_eta, rs_eta, grad_eta):\n",
    "    M = np.zeros(shape=(3,3))\n",
    "\n",
    "    ordering = find_ordering(coord)\n",
    "    orientation = [-1, 1, -1] * sign[ordering]\n",
    "\n",
    "    q_funcs = [q1, q2, q3]\n",
    "\n",
    "    K_local = K_func(np.min(coord[1,:]), (np.max(coord[1, :]) - np.min(coord[1, :])), np.prod(sign), ls_eta, rs_eta, grad_eta)\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            integrand = lambda ys,x: np.array([q_funcs[j](x,y).T @ K_local(x, y) @ q_funcs[i](x,y) for y in np.array(ys)])\n",
    "            inside = lambda xs, n: np.array([integrate.fixed_quad(integrand, 0, 1-x, args=(x,), n=n)[0] for x in np.array(xs)])\n",
    "            M[ordering[i], ordering[j]] = orientation[j] * orientation[i] * integrate.fixed_quad(inside, 0, 1, n=quad_order, args=(quad_order,))[0]\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5ab8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_q(eta_dofs):\n",
    "\n",
    "    # Gradient of eta and pointwise value\n",
    "    grad_eta   = eta_diff @ eta_dofs\n",
    "\n",
    "    faces, cells, sign = sps.find(subdomain.cell_faces)\n",
    "\n",
    "\n",
    "    _, _, _, _, _, node_coords = pp.map_geometry.map_grid(\n",
    "            subdomain, data.get(\"deviation_from_plane_tol\", 1e-5)\n",
    "        )\n",
    "    \n",
    "    dim = subdomain.dim\n",
    "    \n",
    "    node_coords = node_coords[: dim, :]\n",
    "\n",
    "    q_field._compute_cell_face_to_opposite_node(subdomain, data)\n",
    "    cell_face_to_opposite_node = data[q_field.cell_face_to_opposite_node]\n",
    "    \n",
    "    size_A = np.power(subdomain.dim + 1, 2) * subdomain.num_cells\n",
    "    rows_A = np.empty(size_A, dtype=int)\n",
    "    cols_A = np.empty(size_A, dtype=int)\n",
    "    data_A = np.empty(size_A)\n",
    "    idx_A = 0\n",
    "\n",
    "    for c in range(subdomain.num_cells):\n",
    "        # For the current cell retrieve its faces\n",
    "        loc = slice(subdomain.cell_faces.indptr[c], subdomain.cell_faces.indptr[c + 1])\n",
    "        faces_loc = faces[loc]\n",
    "    \n",
    "        eta_cell = np.max(np.where( boundary_grid.nodes[0, :] < sd.cell_centers[0, c] ))\n",
    "\n",
    "\n",
    "        # Get the opposite node id for each face (BUGGED)\n",
    "        # node = cell_face_to_opposite_node[c, :]\n",
    "        node = np.flip(np.sort(cell_face_to_opposite_node[c, :]))\n",
    "\n",
    "        coord_loc = node_coords[:, node]\n",
    "\n",
    "        #print( 'Face: ' + str(faces_loc) + ', Sign: ' + str(sign[loc]) + ', Node: ' + str(node))\n",
    "        #print(coord_loc)\n",
    "\n",
    "        A = local_q(coord_loc, sign[loc], eta_dofs[eta_cell], eta_dofs[eta_cell+1], grad_eta[eta_cell])\n",
    "\n",
    "        # Save values for Hdiv-mass local matrix in the global structure\n",
    "        cols = np.concatenate(faces_loc.size * [[faces_loc]])\n",
    "        loc_idx = slice(idx_A, idx_A + A.size)\n",
    "        rows_A[loc_idx] = cols.T.ravel()\n",
    "        cols_A[loc_idx] = cols.ravel()\n",
    "        data_A[loc_idx] = A.ravel()\n",
    "        idx_A += A.size\n",
    "\n",
    "        #print('')\n",
    "    \n",
    "    return sps.coo_matrix((data_A, (rows_A, cols_A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a074e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.82 ms ± 103 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "local_q(np.array([[0, 1, 0], [0, 0, 1]]), np.array([-1, 1, -1]), 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6036f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0.1\n",
      "Iteration #001, error L2 relative psi:    0.5955119958\n",
      "Iteration #002, error L2 relative psi:    0.0405556413\n",
      "Iteration #003, error L2 relative psi:    0.0021847011\n",
      "Iteration #004, error L2 relative psi:    0.0000937024\n",
      "Iteration #005, error L2 relative psi:    0.0000031921\n",
      "\n",
      "Time 0.2\n",
      "Iteration #001, error L2 relative psi:    0.2051251446\n",
      "Iteration #002, error L2 relative psi:    0.0144614509\n",
      "Iteration #003, error L2 relative psi:    0.0006804954\n",
      "Iteration #004, error L2 relative psi:    0.0000204803\n",
      "Iteration #005, error L2 relative psi:    0.0000004283\n",
      "\n",
      "Time 0.30000000000000004\n",
      "Iteration #001, error L2 relative psi:    0.0718232789\n",
      "Iteration #002, error L2 relative psi:    0.0051465858\n",
      "Iteration #003, error L2 relative psi:    0.0002304917\n",
      "Iteration #004, error L2 relative psi:    0.0000059794\n",
      "\n",
      "Time 0.4\n",
      "Iteration #001, error L2 relative psi:    0.0252071940\n",
      "Iteration #002, error L2 relative psi:    0.0018214468\n",
      "Iteration #003, error L2 relative psi:    0.0000803857\n",
      "Iteration #004, error L2 relative psi:    0.0000019935\n",
      "\n",
      "Time 0.5\n",
      "Iteration #001, error L2 relative psi:    0.0088482458\n",
      "Iteration #002, error L2 relative psi:    0.0006418822\n",
      "Iteration #003, error L2 relative psi:    0.0000282351\n",
      "Iteration #004, error L2 relative psi:    0.0000006910\n",
      "\n",
      "Time 0.6000000000000001\n",
      "Iteration #001, error L2 relative psi:    0.0031059847\n",
      "Iteration #002, error L2 relative psi:    0.0002255955\n",
      "Iteration #003, error L2 relative psi:    0.0000099280\n",
      "Iteration #004, error L2 relative psi:    0.0000002419\n",
      "\n",
      "Time 0.7000000000000001\n",
      "Iteration #001, error L2 relative psi:    0.0010908000\n",
      "Iteration #002, error L2 relative psi:    0.0000791421\n",
      "Iteration #003, error L2 relative psi:    0.0000034919\n",
      "\n",
      "Time 0.8\n",
      "Iteration #001, error L2 relative psi:    0.0003838938\n",
      "Iteration #002, error L2 relative psi:    0.0000277211\n",
      "Iteration #003, error L2 relative psi:    0.0000012301\n",
      "\n",
      "Time 0.9\n",
      "Iteration #001, error L2 relative psi:    0.0001363231\n",
      "Iteration #002, error L2 relative psi:    0.0000096989\n",
      "Iteration #003, error L2 relative psi:    0.0000004353\n",
      "\n",
      "Time 1.0\n",
      "Iteration #001, error L2 relative psi:    0.0000502569\n",
      "Iteration #002, error L2 relative psi:    0.0000034134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time Loop\n",
    "for i in range(1, int(T/dt)+1):\n",
    "    print('Time ' + str(i * dt))\n",
    "    current_time = i * dt\n",
    "\n",
    "    # Prepare the solution at the previous time step and ...\n",
    "    prev = sol[-1].copy()\n",
    "\n",
    "    # Prepare the rhs\n",
    "    rhs = fixed_rhs.copy()\n",
    "    rhs[:dof_q] += bc_val(current_time)\n",
    "    rhs[dof_q:(dof_q+dof_p)] += S_s / dt * M_h @ prev[dof_q:(dof_q+dof_p)]\n",
    "    rhs[-dof_eta:] += (phi / dt * M_gamma @ prev[-dof_eta:] + M_gamma @ gamma_field.interpolate(boundary_grid, lambda x: infiltration(x, current_time)))\n",
    "\n",
    "    debug_saver = pp.Exporter(mdg, str(i) + '_sol', folder_name=os.path.join(output_directory, 'debug'))\n",
    "    save_step(sol[-1], proj_q, proj_psi, proj_eta, debug_saver, 0)\n",
    "    \n",
    "    # Non-linear loop\n",
    "    for k in range(max_iterations_per_step):\n",
    "        mass = mass_q(prev[-dof_eta:]) # pg.face_mass(mdg, q_field)\n",
    "\n",
    "        # Assemble the saddle point problem\n",
    "        spp = sps.bmat([[    mass,            B.T,                           B_gamma.T], \n",
    "                        [      -B, S_s / dt * M_h,                                None],\n",
    "                        [-B_gamma,           None, phi / dt * M_gamma + stab * A_gamma]], format=\"csc\")\n",
    "        \n",
    "        # Prepare the solver\n",
    "        ls = pg.LinearSystem(spp, rhs)\n",
    "        ls.flag_ess_bc(bc_ess_flag(current_time), bc_ess_val(current_time))\n",
    "\n",
    "        current = ls.solve()\n",
    "\n",
    "        # Compute the errors (with eta). Should I consider only psi? Should I compute the error on the \"actual\" psi values or on the dofs\n",
    "        abs_err_psi  = np.sqrt(np.sum(np.power(current[dof_q:] - prev[dof_q:], 2)))\n",
    "        abs_err_prev = np.sqrt(np.sum(np.power(prev[dof_q:], 2)))\n",
    "\n",
    "        print('Iteration #' + format(k+1, '0' + str(ceil(log10(max_iterations_per_step)) + 1) + 'd') \n",
    "              + ', error L2 relative psi: ' + format(abs_err_psi, str(5 + ceil(log10(1 / abs_tol)) + 4) \n",
    "                                                     + '.' + str(ceil(log10(1 / abs_tol)) + 4) + 'f') )\n",
    "        \n",
    "        save_step(current, proj_q, proj_psi, proj_eta, debug_saver, k+1)\n",
    "\n",
    "        if abs_err_psi < abs_tol + rel_tol * abs_err_prev:\n",
    "            break\n",
    "        else:\n",
    "            prev = None\n",
    "            prev = current.copy()\n",
    "\n",
    "    print('')        \n",
    "\n",
    "    sol.append( current.copy() )\n",
    "\n",
    "    save_step(sol[-1], proj_q, proj_psi, proj_eta, saver, i)\n",
    "\n",
    "saver.write_pvd([t * dt for t in range(int(T/dt)+1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cc1db98167c7fd7d55a1da8057731abc6cd6fe154328a2ae319df8aab4e24d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
